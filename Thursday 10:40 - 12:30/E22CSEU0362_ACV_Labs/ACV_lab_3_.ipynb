{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOtnADu92V1U9KaTJ45dYKb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1DYAEjBaFVrXbrbwpbLi-xrLIORopp2Xw"},"id":"7L0WhGCvyMZ0","executionInfo":{"status":"ok","timestamp":1738780488195,"user_tz":-330,"elapsed":6594,"user":{"displayName":"Paras Borase","userId":"13994514769941460648"}},"outputId":"e9399904-ba1c-42e0-a9e4-4a415a9b77fc"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["#!/usr/bin/env python\n","\n","import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from google.colab.patches import cv2_imshow\n","\n","# Task-1\n","# 1. Read and display the image\n","print('Original Image:')\n","image = cv2.imread('zoro.jpg')\n","cv2_imshow(image)\n","\n","# 2. Extract image size\n","height, width, channels = image.shape\n","print(f'Image Size: {width}x{height}, Channels: {channels}')\n","\n","# 3. Calculate image pixels\n","print(f'Total Pixels: {image.size}')\n","\n","# 4. Convert BGR to RGB\n","print('BGR to RGB Conversion:')\n","rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","cv2_imshow(rgb_image)\n","\n","# 5. Convert RGB to Grayscale\n","print('RGB to Grayscale Conversion:')\n","gray_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)\n","cv2_imshow(gray_image)\n","\n","# 6. Grayscale to Binary using threshold\n","print('Grayscale to Binary Conversion:')\n","_, binary_image = cv2.threshold(gray_image, 90, 255, cv2.THRESH_BINARY)\n","cv2_imshow(binary_image)\n","\n","# black pixels\n","black_area = np.sum(binary_image == 0)\n","print(f'Black Pixel Area: {black_area}, Image Size: {binary_image.shape}')\n","\n","\n","\n"]},{"cell_type":"code","source":["# Task-2\n","# Sobel Operator\n","print('Sobel Edge Detection:')\n","sobel_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=3) #Data type for the output image, allowing negative gradients\n","sobel_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3)\n","sobel = cv2.magnitude(sobel_x, sobel_y)\n","cv2_imshow(np.uint8(sobel)) #format\n","\n","# Prewitt Operator\n","print('Prewitt Edge Detection:')\n","kernelx = np.array([[1,0,-1],[1,0,-1],[1,0,-1]])\n","kernely = np.array([[1,1,1],[0,0,0],[-1,-1,-1]])\n","prewitt_x = cv2.filter2D(gray_image, -1, kernelx) #to keep the same depth(datatype) as the source image\n","prewitt_y = cv2.filter2D(gray_image, -1, kernely)\n","prewitt = cv2.add(prewitt_x, prewitt_y)\n","cv2_imshow(prewitt)\n","\n","# Roberts Cross Operator\n","print('Roberts Cross Edge Detection:')\n","roberts_cross_v = np.array([[1, 0], [0, -1]])\n","roberts_cross_h = np.array([[0, 1], [-1, 0]])\n","roberts_v = cv2.filter2D(gray_image, -1, roberts_cross_v)\n","roberts_h = cv2.filter2D(gray_image, -1, roberts_cross_h)\n","roberts = cv2.add(roberts_v, roberts_h)\n","cv2_imshow(roberts)\n","\n","# Canny Edge Detector\n","print('Canny Edge Detection:')\n","canny = cv2.Canny(gray_image, 100, 200) #(Lower threshold,Upper threshold)\n","cv2_imshow(canny)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1DHF_afY7mDqTlBeLP46Xb70rjKzw1sDz"},"id":"JTPVG9xf4jsI","executionInfo":{"status":"ok","timestamp":1738771980741,"user_tz":-330,"elapsed":4951,"user":{"displayName":"Paras Borase","userId":"13994514769941460648"}},"outputId":"8ef13e6e-0799-47f8-da28-0ed3913e6c71"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# Image Segmentation\n","# Global Thresholding\n","print('Global Thresholding for Segmentation:')\n","_, global_thresh = cv2.threshold(gray_image, 90, 255, cv2.THRESH_BINARY)\n","cv2_imshow(global_thresh)\n","\n","# Adaptive Thresholding\n","print('Adaptive Thresholding for Segmentation:')\n","adaptive_thresh = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n","cv2_imshow(adaptive_thresh) #weighted sum of neighborhood values (Gaussian)\n","                            #11: Block size ; 2: Constant subtracted from the weighted sum\n","\n","# Edge Detection for Segmentation (Canny)\n","print('Edge Detection for Segmentation (Canny):')\n","cv2_imshow(canny)\n","\n","# Region-Based Segmentation (Watershed)\n","print('Region-Based Segmentation (Watershed Algorithm):')\n","ret, markers = cv2.connectedComponents(global_thresh)\n","markers = markers + 1\n","markers[global_thresh == 0] = 0\n","markers = cv2.watershed(image, markers)\n","image[markers == -1] = [255, 0, 0]\n","cv2_imshow(image)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1YIYRGEAj9MSRZkJDYbvCwcr9Af3CzFRK"},"id":"o3a6UR_y4kvV","executionInfo":{"status":"ok","timestamp":1738782368429,"user_tz":-330,"elapsed":6374,"user":{"displayName":"Paras Borase","userId":"13994514769941460648"}},"outputId":"c6898143-27c7-4bd3-ebf7-62bb1eab59a8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}