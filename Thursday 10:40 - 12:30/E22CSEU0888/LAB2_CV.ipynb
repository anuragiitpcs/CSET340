{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWdr1n1f1Aij",
        "outputId": "bc3a832f-423d-4e5f-a2cd-1b2c65623ac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JPEG (Quality 90) saved at compressed_images/compressed_90.jpg\n",
            "JPEG (Quality 70) saved at compressed_images/compressed_70.jpg\n",
            "JPEG (Quality 50) saved at compressed_images/compressed_50.jpg\n",
            "PNG (Lossless) saved at compressed_images/compressed_lossless.png\n",
            "Original Image Size: 301030 bytes\n",
            "JPEG 90% Size: 42355 bytes\n",
            "JPEG 70% Size: 22760 bytes\n",
            "JPEG 50% Size: 16633 bytes\n",
            "PNG (Lossless) Size: 248615 bytes\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Load the image\n",
        "image_path = \"/content/test.png\"  # Change this to your image path\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Ensure output directory exists\n",
        "output_dir = \"compressed_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Lossy Compression (JPEG) with different quality levels\n",
        "for quality in [90, 70, 50]:\n",
        "    lossy_path = f\"{output_dir}/compressed_{quality}.jpg\"\n",
        "    cv2.imwrite(lossy_path, image, [cv2.IMWRITE_JPEG_QUALITY, quality])\n",
        "    print(f\"JPEG (Quality {quality}) saved at {lossy_path}\")\n",
        "\n",
        "# Lossless Compression (PNG)\n",
        "lossless_path = f\"{output_dir}/compressed_lossless.png\"\n",
        "cv2.imwrite(lossless_path, image, [cv2.IMWRITE_PNG_COMPRESSION, 9])\n",
        "print(f\"PNG (Lossless) saved at {lossless_path}\")\n",
        "\n",
        "# Compare file sizes\n",
        "original_size = os.path.getsize(image_path)\n",
        "jpeg_sizes = [os.path.getsize(f\"{output_dir}/compressed_{q}.jpg\") for q in [90, 70, 50]]\n",
        "lossless_size = os.path.getsize(lossless_path)\n",
        "\n",
        "print(f\"Original Image Size: {original_size} bytes\")\n",
        "print(f\"JPEG 90% Size: {jpeg_sizes[0]} bytes\")\n",
        "print(f\"JPEG 70% Size: {jpeg_sizes[1]} bytes\")\n",
        "print(f\"JPEG 50% Size: {jpeg_sizes[2]} bytes\")\n",
        "print(f\"PNG (Lossless) Size: {lossless_size} bytes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Be4-pS1y2La1",
        "outputId": "7e3ae80d-9cf2-45ed-e3b4-f8d89baf837d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 54ms/step - accuracy: 0.8774 - loss: 0.4216 - val_accuracy: 0.9819 - val_loss: 0.0566\n",
            "Epoch 2/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 54ms/step - accuracy: 0.9824 - loss: 0.0561 - val_accuracy: 0.9837 - val_loss: 0.0508\n",
            "Epoch 3/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 57ms/step - accuracy: 0.9897 - loss: 0.0339 - val_accuracy: 0.9872 - val_loss: 0.0444\n",
            "Epoch 4/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 52ms/step - accuracy: 0.9921 - loss: 0.0254 - val_accuracy: 0.9887 - val_loss: 0.0376\n",
            "Epoch 5/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - accuracy: 0.9935 - loss: 0.0200 - val_accuracy: 0.9908 - val_loss: 0.0357\n",
            "Epoch 6/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 51ms/step - accuracy: 0.9953 - loss: 0.0132 - val_accuracy: 0.9900 - val_loss: 0.0354\n",
            "Epoch 7/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 51ms/step - accuracy: 0.9958 - loss: 0.0114 - val_accuracy: 0.9901 - val_loss: 0.0369\n",
            "Epoch 8/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - accuracy: 0.9978 - loss: 0.0076 - val_accuracy: 0.9918 - val_loss: 0.0322\n",
            "Epoch 9/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 54ms/step - accuracy: 0.9977 - loss: 0.0070 - val_accuracy: 0.9902 - val_loss: 0.0428\n",
            "Epoch 10/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 51ms/step - accuracy: 0.9975 - loss: 0.0074 - val_accuracy: 0.9916 - val_loss: 0.0390\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
            "MNIST Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       980\n",
            "           1       1.00      1.00      1.00      1135\n",
            "           2       0.98      1.00      0.99      1032\n",
            "           3       0.98      0.99      0.99      1010\n",
            "           4       0.99      0.99      0.99       982\n",
            "           5       0.98      0.98      0.98       892\n",
            "           6       1.00      0.98      0.99       958\n",
            "           7       0.99      0.99      0.99      1028\n",
            "           8       0.99      0.99      0.99       974\n",
            "           9       0.99      0.98      0.99      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 978    0    0    0    0    0    0    1    1    0]\n",
            " [   0 1133    0    1    0    0    0    1    0    0]\n",
            " [   1    0 1027    0    1    0    0    3    0    0]\n",
            " [   0    0    3 1004    0    3    0    0    0    0]\n",
            " [   0    0    1    0  975    0    1    1    0    4]\n",
            " [   1    0    0   10    0  878    1    0    2    0]\n",
            " [   2    3    0    0    1    7  943    0    2    0]\n",
            " [   0    1    9    1    0    0    0 1015    1    1]\n",
            " [   2    0    3    1    0    1    0    2  964    1]\n",
            " [   0    0    0    4    6    4    1    6    0  988]]\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 86ms/step - accuracy: 0.3166 - loss: 1.8515 - val_accuracy: 0.5101 - val_loss: 1.3638\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 88ms/step - accuracy: 0.5396 - loss: 1.2786 - val_accuracy: 0.5960 - val_loss: 1.1471\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 92ms/step - accuracy: 0.6090 - loss: 1.1063 - val_accuracy: 0.6327 - val_loss: 1.0603\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 85ms/step - accuracy: 0.6477 - loss: 0.9998 - val_accuracy: 0.6369 - val_loss: 1.0272\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 88ms/step - accuracy: 0.6866 - loss: 0.9048 - val_accuracy: 0.6590 - val_loss: 0.9796\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 90ms/step - accuracy: 0.7064 - loss: 0.8417 - val_accuracy: 0.6648 - val_loss: 0.9665\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 88ms/step - accuracy: 0.7323 - loss: 0.7662 - val_accuracy: 0.6920 - val_loss: 0.9025\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 85ms/step - accuracy: 0.7505 - loss: 0.7121 - val_accuracy: 0.6961 - val_loss: 0.8815\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 87ms/step - accuracy: 0.7640 - loss: 0.6741 - val_accuracy: 0.6925 - val_loss: 0.8925\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 86ms/step - accuracy: 0.7782 - loss: 0.6247 - val_accuracy: 0.7079 - val_loss: 0.8798\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step\n",
            "CIFAR-10 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.78      0.75      1000\n",
            "           1       0.81      0.85      0.83      1000\n",
            "           2       0.63      0.58      0.60      1000\n",
            "           3       0.53      0.53      0.53      1000\n",
            "           4       0.65      0.65      0.65      1000\n",
            "           5       0.74      0.45      0.56      1000\n",
            "           6       0.72      0.83      0.77      1000\n",
            "           7       0.71      0.78      0.74      1000\n",
            "           8       0.74      0.85      0.79      1000\n",
            "           9       0.82      0.76      0.78      1000\n",
            "\n",
            "    accuracy                           0.71     10000\n",
            "   macro avg       0.71      0.71      0.70     10000\n",
            "weighted avg       0.71      0.71      0.70     10000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[784  26  29  11  15   1  10  13  83  28]\n",
            " [ 17 849   7   7   2   1   9   7  44  57]\n",
            " [ 84  11 578  60  85  27  86  37  25   7]\n",
            " [ 27  18  69 533  85  79  88  53  36  12]\n",
            " [ 32   6  55  59 651  18  64  90  18   7]\n",
            " [ 21   7  66 234  58 450  45  85  19  15]\n",
            " [  8   6  47  42  34   5 834   8   8   8]\n",
            " [ 20   9  43  33  62  24   8 776  13  12]\n",
            " [ 70  28   6   9   4   2   4   3 851  23]\n",
            " [ 36  93  11  14   7   3   7  26  48 755]]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocessing MNIST\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "\n",
        "# Build CNN Model for MNIST\n",
        "def build_mnist_cnn():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train MNIST Model\n",
        "mnist_model = build_mnist_cnn()\n",
        "mnist_model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate MNIST Model\n",
        "y_pred_mnist = mnist_model.predict(x_test)\n",
        "y_pred_classes_mnist = np.argmax(y_pred_mnist, axis=1)\n",
        "y_true_mnist = np.argmax(y_test, axis=1)\n",
        "print(\"MNIST Classification Report:\")\n",
        "print(classification_report(y_true_mnist, y_pred_classes_mnist))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true_mnist, y_pred_classes_mnist))\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Preprocessing CIFAR-10\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Build CNN Model for CIFAR-10\n",
        "def build_cifar10_cnn():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(128, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train CIFAR-10 Model\n",
        "cifar10_model = build_cifar10_cnn()\n",
        "cifar10_model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate CIFAR-10 Model\n",
        "y_pred_cifar10 = cifar10_model.predict(x_test)\n",
        "y_pred_classes_cifar10 = np.argmax(y_pred_cifar10, axis=1)\n",
        "y_true_cifar10 = np.argmax(y_test, axis=1)\n",
        "print(\"CIFAR-10 Classification Report:\")\n",
        "print(classification_report(y_true_cifar10, y_pred_classes_cifar10))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true_cifar10, y_pred_classes_cifar10))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}