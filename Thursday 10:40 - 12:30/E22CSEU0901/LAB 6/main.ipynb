{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We are using YOLO for detection. So we adjust the dataset to its format.\n",
    "\n",
    "\n",
    "Imports necessary libraries: os (file operations), pandas (data handling), and cv2 (image processing).\n",
    "\n",
    "Reads the CSV file containing annotations for license plate detection.\n",
    "\n",
    "Specifies folders where images and labels are stored.\n",
    "\n",
    "Ensures the label folder exists, creating it if necessary.\n",
    "\n",
    "Iterates through the CSV file and reads image annotations.\n",
    "\n",
    "Converts bounding box coordinates to YOLO format:\n",
    "(x_center, y_center): Center of the bounding box (normalized).\n",
    "(bbox_width, bbox_height): Width and height of the bounding box (normalized).\n",
    "\n",
    "Saves the converted labels in a .txt file, one per image.\n",
    "\n",
    "Output: \"CSV converted to YOLO format!\" VOILA! successful conversion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV converted to YOLO format!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "# Load CSV file\n",
    "csv_path = \"Licplatesdetection_train.csv\"  # Update with actual path\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Define input/output folders\n",
    "image_folder = \"data_detection/images\"\n",
    "label_folder = \"data_detection/labels\"\n",
    "\n",
    "os.makedirs(label_folder, exist_ok=True)\n",
    "\n",
    "# Convert CSV to YOLO format\n",
    "for index, row in df.iterrows():\n",
    "    img_path = os.path.join(image_folder, row[\"img_id\"])\n",
    "    img = cv2.imread(img_path)\n",
    "    h, w, _ = img.shape  # Get image dimensions\n",
    "\n",
    "    # Convert bounding box to YOLO format\n",
    "    xmin, ymin, xmax, ymax = row[\"xmin\"], row[\"ymin\"], row[\"xmax\"], row[\"ymax\"]\n",
    "    x_center = (xmin + xmax) / (2 * w)\n",
    "    y_center = (ymin + ymax) / (2 * h)\n",
    "    bbox_width = (xmax - xmin) / w\n",
    "    bbox_height = (ymax - ymin) / h\n",
    "\n",
    "    # YOLO format: class_id x_center y_center width height\n",
    "    label_path = os.path.join(label_folder, row[\"img_id\"].replace(\".jpg\", \".txt\"))\n",
    "    with open(label_path, \"w\") as f:\n",
    "        f.write(f\"0 {x_center} {y_center} {bbox_width} {bbox_height}\\n\")  # Class 0 for license plates\n",
    "\n",
    "print(\"CSV converted to YOLO format!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set created successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define paths\n",
    "train_img_folder = \"data_detection/train/images\"\n",
    "train_lbl_folder = \"data_detection/train/labels\"\n",
    "val_img_folder = \"dataset/val/images\"\n",
    "val_lbl_folder = \"dataset/val/labels\"\n",
    "\n",
    "# Create validation folders\n",
    "os.makedirs(val_img_folder, exist_ok=True)\n",
    "os.makedirs(val_lbl_folder, exist_ok=True)\n",
    "\n",
    "# Get all images\n",
    "all_images = os.listdir(train_img_folder)\n",
    "random.shuffle(all_images)\n",
    "\n",
    "# Move 20% of images to validation\n",
    "val_size = int(0.2 * len(all_images))\n",
    "val_images = all_images[:val_size]\n",
    "\n",
    "for img_name in val_images:\n",
    "    # Move image\n",
    "    shutil.move(os.path.join(train_img_folder, img_name), os.path.join(val_img_folder, img_name))\n",
    "\n",
    "    # Move corresponding label file\n",
    "    label_name = img_name.replace(\".jpg\", \".txt\")  # Adjust extension if needed\n",
    "    shutil.move(os.path.join(train_lbl_folder, label_name), os.path.join(val_lbl_folder, label_name))\n",
    "\n",
    "print(\"Validation set created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import settings\n",
    "settings.reset()  # Clears cached dataset paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train path exists: True\n",
      "Validation path exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_path = \"D:/Projects/DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001/data_detection/train/images\"\n",
    "val_path = \"D:/Projects/DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001/data_detection/val/images\"\n",
    "\n",
    "print(\"Train path exists:\", os.path.exists(train_path))\n",
    "print(\"Validation path exists:\", os.path.exists(val_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.92 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.15  Python-3.12.4 torch-2.6.0+cpu CPU (AMD Ryzen 7 6800HS with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=data-l.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train4\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 249 layers, 2,690,403 parameters, 2,690,387 gradients, 6.9 GFLOPs\n",
      "\n",
      "Transferred 313/391 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train4', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\train\\labels... 720 images, 0 backgrounds, 0 corrupt: 100%|██████████| 720/720 [00:00<00:00, 1369.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\val\\labels... 180 images, 0 backgrounds, 0 corrupt: 100%|██████████| 180/180 [00:00<00:00, 1796.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\val\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train4\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 63 weight(decay=0.0), 70 weight(decay=0.0005), 69 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train4\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G       1.25      2.809       1.05         35        640: 100%|██████████| 45/45 [02:31<00:00,  3.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:12<00:00,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180    0.00331      0.994      0.446      0.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50         0G      1.197      1.525      1.012         20        640: 100%|██████████| 45/45 [02:22<00:00,  3.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:10<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180    0.00306      0.917      0.402      0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50         0G      1.237      1.407      1.056         28        640: 100%|██████████| 45/45 [02:19<00:00,  3.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:10<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.971      0.915      0.978      0.656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50         0G      1.184      1.202      1.044         30        640: 100%|██████████| 45/45 [02:17<00:00,  3.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:10<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.865      0.944      0.943      0.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50         0G      1.124       1.01      1.013         34        640: 100%|██████████| 45/45 [02:18<00:00,  3.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.955      0.972      0.983      0.673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50         0G      1.109     0.8978      1.007         31        640: 100%|██████████| 45/45 [02:16<00:00,  3.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.936      0.922      0.968      0.668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50         0G      1.038     0.8008     0.9879         30        640: 100%|██████████| 45/45 [02:13<00:00,  2.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.984      0.933       0.99      0.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50         0G      1.028     0.7791     0.9726         20        640: 100%|██████████| 45/45 [02:12<00:00,  2.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.983      0.948      0.989      0.709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50         0G      1.049     0.7315     0.9825         32        640: 100%|██████████| 45/45 [02:12<00:00,  2.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.955      0.947      0.982      0.689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50         0G      1.039     0.7287     0.9891         26        640: 100%|██████████| 45/45 [02:11<00:00,  2.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.967      0.971       0.99      0.718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50         0G      1.019     0.6631     0.9678         23        640: 100%|██████████| 45/45 [02:12<00:00,  2.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.977      0.928      0.989      0.677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50         0G       1.01     0.6605     0.9745         28        640: 100%|██████████| 45/45 [02:12<00:00,  2.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.972      0.978      0.993      0.737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50         0G     0.9702      0.614     0.9539         29        640: 100%|██████████| 45/45 [02:12<00:00,  2.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.993      0.972      0.994      0.681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50         0G      1.014     0.6292     0.9739         24        640: 100%|██████████| 45/45 [02:12<00:00,  2.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.983      0.977      0.992      0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50         0G     0.9421     0.5921     0.9427         29        640: 100%|██████████| 45/45 [02:12<00:00,  2.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.978      0.985      0.994      0.747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50         0G     0.9469     0.5944     0.9637         25        640: 100%|██████████| 45/45 [02:11<00:00,  2.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.993      0.967      0.994      0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50         0G     0.9246     0.5769     0.9519         27        640: 100%|██████████| 45/45 [02:11<00:00,  2.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.994      0.983      0.994      0.747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50         0G     0.9285     0.5653     0.9414         29        640: 100%|██████████| 45/45 [02:16<00:00,  3.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180          1      0.967      0.994      0.738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50         0G      0.914     0.5425     0.9322         34        640: 100%|██████████| 45/45 [02:27<00:00,  3.28s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:11<00:00,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.986      0.972      0.994       0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50         0G     0.9404     0.5428     0.9348         26        640: 100%|██████████| 45/45 [02:35<00:00,  3.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:10<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.996      0.978      0.995      0.748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50         0G     0.8859     0.5277     0.9233         27        640: 100%|██████████| 45/45 [03:07<00:00,  4.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:17<00:00,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.989      0.974      0.994      0.754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50         0G     0.8704     0.5052     0.9217         30        640: 100%|██████████| 45/45 [04:37<00:00,  6.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:17<00:00,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.995      0.983      0.995      0.747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50         0G     0.9242     0.5357     0.9311         32        640: 100%|██████████| 45/45 [04:32<00:00,  6.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:18<00:00,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.994      0.977      0.994       0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50         0G     0.8776     0.5113     0.9266         28        640: 100%|██████████| 45/45 [04:25<00:00,  5.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:12<00:00,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.987      0.983      0.994      0.746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50         0G     0.8828     0.5074     0.9278         32        640: 100%|██████████| 45/45 [03:21<00:00,  4.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:14<00:00,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.985      0.989      0.994      0.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50         0G     0.8908     0.5146     0.9277         32        640: 100%|██████████| 45/45 [04:32<00:00,  6.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:18<00:00,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.989      0.981      0.994      0.753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50         0G     0.8523     0.4906     0.9257         32        640: 100%|██████████| 45/45 [04:02<00:00,  5.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:17<00:00,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.989      0.977      0.994      0.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50         0G     0.8581     0.4914     0.9158         27        640: 100%|██████████| 45/45 [04:29<00:00,  5.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:18<00:00,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.973      0.972      0.992      0.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50         0G     0.8496     0.4898     0.9176         31        640: 100%|██████████| 45/45 [03:17<00:00,  4.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:11<00:00,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.967      0.984      0.993      0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50         0G     0.8616     0.4867     0.9128         27        640: 100%|██████████| 45/45 [03:59<00:00,  5.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:16<00:00,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.994      0.994      0.995      0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50         0G     0.8463     0.4816      0.915         23        640: 100%|██████████| 45/45 [04:48<00:00,  6.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:18<00:00,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.994      0.988      0.995      0.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50         0G     0.8271     0.4722     0.9133         28        640: 100%|██████████| 45/45 [04:41<00:00,  6.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:18<00:00,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.982      0.989      0.994      0.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50         0G     0.8224     0.4514     0.9102         32        640: 100%|██████████| 45/45 [03:55<00:00,  5.24s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:11<00:00,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.973      0.992      0.994      0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50         0G     0.8059     0.4584     0.9073         28        640: 100%|██████████| 45/45 [03:31<00:00,  4.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:17<00:00,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.989      0.994      0.995      0.786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50         0G     0.7974     0.4496     0.9068         30        640: 100%|██████████| 45/45 [04:35<00:00,  6.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:16<00:00,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.978      0.994      0.995      0.789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50         0G     0.8116     0.4476     0.9065         32        640: 100%|██████████| 45/45 [04:31<00:00,  6.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:17<00:00,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.975      0.989      0.994      0.783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50         0G     0.8225     0.4566      0.904         36        640: 100%|██████████| 45/45 [03:45<00:00,  5.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:17<00:00,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180          1      0.976      0.995      0.782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50         0G     0.8054      0.443     0.9065         37        640: 100%|██████████| 45/45 [04:43<00:00,  6.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:16<00:00,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.994      0.994      0.995      0.791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50         0G     0.7686     0.4212     0.8987         27        640: 100%|██████████| 45/45 [04:01<00:00,  5.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:18<00:00,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.988      0.994      0.995       0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50         0G     0.7849     0.4318     0.9009         29        640: 100%|██████████| 45/45 [04:37<00:00,  6.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:18<00:00,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.977      0.994      0.995      0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50         0G     0.7315     0.3945     0.8768         16        640: 100%|██████████| 45/45 [04:22<00:00,  5.83s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:18<00:00,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.994      0.994      0.995      0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50         0G     0.7361     0.3852     0.8821         16        640: 100%|██████████| 45/45 [04:33<00:00,  6.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:18<00:00,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.993          1      0.995      0.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50         0G     0.7117     0.3693     0.8702         16        640: 100%|██████████| 45/45 [04:27<00:00,  5.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:16<00:00,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.994          1      0.995      0.792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50         0G     0.7108     0.3766     0.8758         16        640: 100%|██████████| 45/45 [03:53<00:00,  5.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:11<00:00,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.994      0.998      0.995      0.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50         0G     0.6939     0.3697     0.8716         16        640: 100%|██████████| 45/45 [03:53<00:00,  5.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:17<00:00,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.994          1      0.995      0.793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50         0G     0.6736     0.3577     0.8562         16        640: 100%|██████████| 45/45 [04:15<00:00,  5.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:15<00:00,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.994          1      0.995      0.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50         0G     0.6707     0.3562     0.8646         16        640: 100%|██████████| 45/45 [03:57<00:00,  5.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:17<00:00,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.996      0.994      0.995      0.801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50         0G     0.6532     0.3467     0.8584         16        640: 100%|██████████| 45/45 [04:16<00:00,  5.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:11<00:00,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.994          1      0.995      0.797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50         0G      0.653     0.3475     0.8648         16        640: 100%|██████████| 45/45 [02:19<00:00,  3.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:10<00:00,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.994      0.999      0.995      0.801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50         0G     0.6478      0.336     0.8683         16        640: 100%|██████████| 45/45 [02:12<00:00,  2.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.994          1      0.995      0.805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 2.993 hours.\n",
      "Optimizer stripped from runs\\detect\\train4\\weights\\last.pt, 5.6MB\n",
      "Optimizer stripped from runs\\detect\\train4\\weights\\best.pt, 5.6MB\n",
      "\n",
      "Validating runs\\detect\\train4\\weights\\best.pt...\n",
      "Ultralytics 8.3.15  Python-3.12.4 torch-2.6.0+cpu CPU (AMD Ryzen 7 6800HS with Radeon Graphics)\n",
      "Model summary (fused): 186 layers, 2,684,563 parameters, 0 gradients, 6.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        180        180      0.994          1      0.995      0.804\n",
      "Speed: 0.7ms preprocess, 35.7ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train4\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000019BE69ADAC0>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.99448,     0.99448,     0.99448,     0.99448,     0.99448,     0.99448,     0.99448,     0.99448,     0.99448,     0.99448,     0.99448,     0.99448,\n",
       "            0.99448,     0.99448,     0.99448,     0.99448,     0.99448,     0.99448,     0.99448,     0.99448,     0.99448,     0.99448,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.80357,     0.80357,     0.85894,     0.89276,     0.90956,     0.92133,     0.92797,     0.93285,     0.93491,     0.93823,     0.93978,     0.94288,     0.94348,     0.94408,     0.94468,     0.94775,     0.94933,     0.95161,     0.95323,     0.95443,     0.95778,     0.95934,     0.96322,\n",
       "            0.96516,      0.9671,     0.96894,     0.97037,     0.97044,     0.97051,     0.97058,     0.97065,     0.97072,      0.9708,     0.97087,     0.97094,     0.97101,     0.97108,     0.97116,     0.97123,      0.9713,     0.97137,     0.97144,     0.97151,     0.97159,     0.97166,     0.97173,\n",
       "             0.9718,     0.97187,     0.97195,     0.97202,     0.97209,     0.97216,     0.97223,      0.9723,     0.97238,     0.97245,     0.97252,     0.97259,     0.97266,     0.97273,      0.9728,     0.97288,     0.97295,      0.9751,     0.97591,     0.97626,     0.97661,     0.97696,     0.97731,\n",
       "            0.97766,     0.97802,     0.97839,     0.97884,     0.97928,     0.97973,     0.98017,     0.98061,     0.98126,     0.98238,      0.9835,     0.98366,     0.98372,     0.98378,     0.98384,     0.98391,     0.98397,     0.98403,     0.98409,     0.98415,     0.98421,     0.98427,     0.98433,\n",
       "            0.98439,     0.98445,     0.98451,     0.98457,     0.98463,      0.9847,     0.98476,     0.98482,     0.98488,     0.98494,       0.985,     0.98506,     0.98512,     0.98518,     0.98524,      0.9853,     0.98536,     0.98542,     0.98549,     0.98555,     0.98561,     0.98567,     0.98573,\n",
       "            0.98579,     0.98585,     0.98591,     0.98597,     0.98603,     0.98609,     0.98615,     0.98621,     0.98627,     0.98643,     0.98668,     0.98692,     0.98717,     0.98741,     0.98765,      0.9879,     0.98814,     0.98839,     0.98863,     0.98887,     0.98904,     0.98911,     0.98918,\n",
       "            0.98925,     0.98931,     0.98938,     0.98945,     0.98952,     0.98959,     0.98966,     0.98972,     0.98979,     0.98986,     0.98993,        0.99,     0.99007,     0.99013,      0.9902,     0.99027,     0.99034,     0.99041,     0.99048,     0.99054,     0.99061,     0.99068,     0.99075,\n",
       "            0.99082,     0.99089,     0.99095,     0.99102,     0.99109,     0.99116,     0.99123,     0.99129,     0.99136,     0.99143,      0.9915,     0.99157,     0.99163,      0.9917,     0.99175,     0.99178,     0.99181,     0.99184,     0.99187,      0.9919,     0.99193,     0.99196,     0.99199,\n",
       "            0.99202,     0.99205,     0.99208,     0.99211,     0.99214,     0.99217,      0.9922,     0.99222,     0.99225,     0.99228,     0.99231,     0.99234,     0.99237,      0.9924,     0.99243,     0.99246,     0.99249,     0.99252,     0.99255,     0.99258,     0.99261,     0.99264,     0.99267,\n",
       "             0.9927,     0.99273,     0.99276,     0.99279,     0.99282,     0.99285,     0.99288,     0.99291,     0.99293,     0.99296,     0.99299,     0.99302,     0.99305,     0.99308,     0.99311,     0.99314,     0.99317,      0.9932,     0.99323,     0.99326,     0.99329,     0.99332,     0.99335,\n",
       "            0.99338,     0.99341,     0.99344,     0.99347,      0.9935,     0.99353,     0.99356,     0.99358,     0.99361,     0.99364,     0.99367,      0.9937,     0.99373,     0.99376,     0.99379,     0.99382,     0.99385,     0.99388,     0.99391,     0.99394,     0.99397,       0.994,     0.99403,\n",
       "            0.99406,     0.99409,     0.99412,     0.99415,     0.99417,      0.9942,     0.99423,     0.99426,     0.99429,     0.99432,     0.99435,     0.99438,     0.99441,     0.99444,     0.99447,     0.99449,     0.99452,     0.99454,     0.99456,     0.99458,     0.99461,     0.99463,     0.99465,\n",
       "            0.99467,     0.99469,     0.99472,     0.99474,     0.99476,     0.99478,     0.99481,     0.99483,     0.99485,     0.99487,      0.9949,     0.99492,     0.99494,     0.99496,     0.99498,     0.99501,     0.99503,     0.99505,     0.99507,      0.9951,     0.99512,     0.99514,     0.99516,\n",
       "            0.99519,     0.99521,     0.99523,     0.99525,     0.99527,      0.9953,     0.99532,     0.99534,     0.99536,     0.99539,     0.99541,     0.99543,     0.99545,     0.99548,      0.9955,     0.99552,     0.99554,     0.99556,     0.99559,     0.99561,     0.99563,     0.99565,     0.99568,\n",
       "             0.9957,     0.99572,     0.99574,     0.99577,     0.99579,     0.99581,     0.99583,     0.99585,     0.99588,      0.9959,     0.99592,     0.99594,     0.99597,     0.99599,     0.99601,     0.99603,     0.99605,     0.99608,      0.9961,     0.99612,     0.99614,     0.99617,     0.99619,\n",
       "            0.99621,     0.99623,     0.99626,     0.99628,      0.9963,     0.99632,     0.99634,     0.99637,     0.99639,     0.99641,     0.99643,     0.99646,     0.99648,      0.9965,     0.99652,     0.99654,     0.99657,     0.99659,     0.99661,     0.99663,     0.99666,     0.99668,      0.9967,\n",
       "            0.99672,     0.99674,     0.99677,     0.99679,     0.99681,     0.99683,     0.99686,     0.99688,      0.9969,     0.99692,     0.99694,     0.99697,     0.99699,     0.99701,     0.99703,     0.99706,     0.99708,      0.9971,     0.99712,     0.99714,     0.99717,     0.99719,     0.99721,\n",
       "            0.99723,     0.99721,     0.99719,     0.99717,     0.99715,     0.99713,     0.99711,     0.99709,     0.99707,     0.99704,     0.99702,       0.997,     0.99698,     0.99696,     0.99694,     0.99692,      0.9969,     0.99688,     0.99686,     0.99684,     0.99682,      0.9968,     0.99678,\n",
       "            0.99676,     0.99674,     0.99672,      0.9967,     0.99668,     0.99666,     0.99664,     0.99662,      0.9966,     0.99658,     0.99656,     0.99654,     0.99652,      0.9965,     0.99648,     0.99646,     0.99644,     0.99642,      0.9964,     0.99638,     0.99636,     0.99634,     0.99632,\n",
       "             0.9963,     0.99628,     0.99626,     0.99624,     0.99622,      0.9962,     0.99618,     0.99616,     0.99614,     0.99611,     0.99609,     0.99607,     0.99605,     0.99603,     0.99601,     0.99599,     0.99597,     0.99595,     0.99593,     0.99591,     0.99589,     0.99587,     0.99585,\n",
       "            0.99583,     0.99581,     0.99579,     0.99577,     0.99575,     0.99573,     0.99571,     0.99569,     0.99567,     0.99565,     0.99563,     0.99561,     0.99559,     0.99557,     0.99555,     0.99553,     0.99551,     0.99549,     0.99547,     0.99545,     0.99543,     0.99541,     0.99539,\n",
       "            0.99537,     0.99535,     0.99533,      0.9953,     0.99528,     0.99526,     0.99524,     0.99522,      0.9952,     0.99518,     0.99516,     0.99514,     0.99512,      0.9951,     0.99508,     0.99506,     0.99504,     0.99502,       0.995,     0.99498,     0.99496,     0.99494,     0.99492,\n",
       "             0.9949,     0.99488,     0.99486,     0.99484,     0.99482,      0.9948,     0.99478,     0.99476,     0.99474,     0.99472,      0.9947,     0.99468,     0.99466,     0.99464,     0.99462,      0.9946,     0.99457,     0.99455,     0.99453,     0.99451,     0.99449,     0.99447,     0.99445,\n",
       "             0.9944,     0.99432,     0.99424,     0.99416,     0.99408,     0.99399,     0.99391,     0.99383,     0.99375,     0.99367,     0.99359,     0.99351,     0.99343,     0.99335,     0.99327,     0.99319,     0.99311,     0.99302,     0.99294,     0.99286,     0.99278,      0.9927,     0.99262,\n",
       "            0.99254,     0.99246,     0.99238,      0.9923,     0.99222,     0.99213,     0.99205,     0.99197,     0.99189,     0.99181,     0.99173,     0.99165,     0.99159,     0.99154,     0.99149,     0.99143,     0.99138,     0.99133,     0.99127,     0.99122,     0.99116,     0.99111,     0.99106,\n",
       "              0.991,     0.99095,      0.9909,     0.99084,     0.99079,     0.99074,     0.99068,     0.99063,     0.99058,     0.99052,     0.99047,     0.99041,     0.99036,     0.99031,     0.99025,      0.9902,     0.99015,     0.99009,     0.99004,     0.98999,     0.98993,     0.98988,     0.98982,\n",
       "            0.98977,     0.98972,     0.98966,     0.98961,     0.98956,      0.9895,     0.98945,     0.98939,     0.98934,     0.98929,     0.98923,     0.98918,     0.98913,     0.98907,     0.98902,     0.98896,     0.98891,     0.98886,     0.98876,     0.98862,     0.98847,     0.98833,     0.98818,\n",
       "            0.98804,     0.98789,     0.98775,     0.98761,     0.98746,     0.98732,     0.98717,     0.98703,     0.98688,     0.98674,     0.98659,     0.98645,      0.9863,     0.98615,     0.98601,     0.98601,     0.98603,     0.98605,     0.98607,     0.98609,     0.98611,     0.98613,     0.98615,\n",
       "            0.98617,     0.98618,      0.9862,     0.98622,     0.98624,     0.98626,     0.98628,      0.9863,     0.98632,     0.98634,     0.98636,     0.98638,      0.9864,     0.98641,     0.98643,     0.98645,     0.98647,     0.98649,     0.98651,     0.98653,     0.98655,     0.98657,     0.98659,\n",
       "            0.98661,     0.98663,     0.98664,     0.98666,     0.98668,      0.9867,     0.98672,     0.98674,     0.98676,     0.98678,      0.9868,     0.98682,     0.98684,     0.98686,     0.98687,     0.98689,     0.98691,     0.98693,     0.98695,     0.98697,     0.98699,     0.98701,     0.98703,\n",
       "            0.98705,     0.98707,     0.98709,      0.9871,     0.98712,     0.98714,     0.98716,     0.98718,      0.9872,     0.98722,     0.98724,     0.98726,     0.98728,      0.9873,     0.98732,     0.98733,     0.98735,     0.98737,     0.98739,     0.98741,     0.98743,     0.98745,     0.98747,\n",
       "            0.98749,     0.98751,     0.98753,     0.98755,     0.98756,     0.98758,      0.9876,     0.98762,     0.98764,     0.98766,     0.98768,      0.9877,     0.98772,     0.98774,     0.98776,     0.98777,     0.98779,     0.98781,     0.98783,     0.98785,     0.98787,     0.98789,     0.98791,\n",
       "            0.98793,     0.98795,     0.98797,     0.98799,       0.988,     0.98802,     0.98804,     0.98806,     0.98808,      0.9881,     0.98812,     0.98814,     0.98816,     0.98818,      0.9882,     0.98821,     0.98823,     0.98825,     0.98827,     0.98829,     0.98831,     0.98833,     0.98835,\n",
       "            0.98837,     0.98839,     0.98841,     0.98842,     0.98844,     0.98846,     0.98848,      0.9885,     0.98852,     0.98854,     0.98856,     0.98858,      0.9886,     0.98862,     0.98863,     0.98865,     0.98867,     0.98869,     0.98871,     0.98873,     0.98875,     0.98868,     0.98835,\n",
       "            0.98801,     0.98767,     0.98734,       0.987,     0.98666,     0.98632,     0.98599,     0.98296,     0.98264,     0.98232,     0.98201,     0.98169,     0.98137,     0.98105,     0.98073,     0.98041,      0.9787,     0.97616,     0.97467,     0.97109,     0.96822,      0.9678,     0.96739,\n",
       "            0.96698,     0.96656,     0.96615,     0.96574,      0.9653,     0.96483,     0.96437,      0.9639,     0.96344,     0.96297,     0.96243,     0.96092,     0.95948,     0.95873,     0.95798,     0.95723,     0.95645,     0.95516,     0.95388,     0.95325,     0.95292,     0.95258,     0.95225,\n",
       "            0.95191,     0.95157,     0.95124,      0.9509,     0.95056,     0.94941,     0.94778,     0.94685,     0.94615,     0.94545,     0.94475,     0.94385,     0.94253,     0.94121,     0.93985,     0.93849,     0.93716,     0.93586,     0.93424,     0.93184,     0.93005,     0.92783,     0.92428,\n",
       "            0.92148,     0.91434,     0.89913,     0.88981,     0.87843,     0.87652,     0.87394,     0.86585,     0.84955,     0.83879,     0.82719,     0.82465,     0.80937,     0.79397,     0.77726,     0.76644,     0.75959,     0.73346,     0.71547,      0.7108,     0.70663,     0.69138,     0.67961,\n",
       "            0.66638,     0.65044,     0.64156,     0.63289,     0.62865,     0.62405,     0.61028,     0.59659,     0.58532,     0.56841,     0.56154,     0.54607,     0.50822,     0.47638,     0.45965,     0.43647,     0.41156,     0.40255,     0.36574,     0.33687,     0.31861,     0.29757,     0.27917,\n",
       "            0.27034,     0.23156,     0.20272,     0.19728,     0.19383,     0.18796,     0.16226,      0.1571,     0.15079,     0.14244,     0.12498,     0.12117,     0.11733,    0.093342,    0.074757,    0.072582,    0.070401,    0.068216,    0.066025,    0.050765,    0.042042,    0.040446,    0.038847,\n",
       "           0.037246,    0.035642,    0.034035,    0.030889,    0.022373,    0.021405,    0.020804,    0.020202,    0.019601,    0.018998,    0.018396,    0.017793,     0.01719,    0.016586,    0.015982,    0.015377,    0.014773,    0.014167,    0.013562,    0.012956,     0.01235,    0.011743,    0.011136,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.67164,     0.67164,     0.75276,     0.80629,     0.83413,     0.85414,     0.86562,     0.87415,     0.87778,     0.88365,     0.88639,     0.89194,     0.89301,     0.89409,     0.89516,     0.90069,     0.90355,     0.90768,     0.91064,     0.91284,     0.91898,     0.92185,     0.92904,\n",
       "            0.93266,      0.9363,     0.93975,     0.94244,     0.94257,     0.94271,     0.94284,     0.94298,     0.94311,     0.94325,     0.94339,     0.94352,     0.94366,     0.94379,     0.94393,     0.94406,      0.9442,     0.94434,     0.94447,     0.94461,     0.94474,     0.94488,     0.94501,\n",
       "            0.94515,     0.94529,     0.94542,     0.94556,     0.94569,     0.94583,     0.94596,      0.9461,     0.94624,     0.94637,     0.94651,     0.94664,     0.94678,     0.94691,     0.94705,     0.94719,     0.94732,     0.95141,     0.95295,     0.95362,     0.95429,     0.95496,     0.95563,\n",
       "            0.95631,     0.95698,      0.9577,     0.95856,     0.95941,     0.96026,     0.96111,     0.96197,      0.9632,     0.96537,     0.96753,     0.96785,     0.96797,     0.96808,      0.9682,     0.96832,     0.96844,     0.96856,     0.96867,     0.96879,     0.96891,     0.96903,     0.96915,\n",
       "            0.96926,     0.96938,      0.9695,     0.96962,     0.96973,     0.96985,     0.96997,     0.97009,     0.97021,     0.97032,     0.97044,     0.97056,     0.97068,      0.9708,     0.97091,     0.97103,     0.97115,     0.97127,     0.97139,      0.9715,     0.97162,     0.97174,     0.97186,\n",
       "            0.97197,     0.97209,     0.97221,     0.97233,     0.97245,     0.97256,     0.97268,      0.9728,     0.97292,     0.97323,      0.9737,     0.97418,     0.97466,     0.97513,     0.97561,     0.97609,     0.97656,     0.97704,     0.97752,     0.97799,     0.97832,     0.97845,     0.97859,\n",
       "            0.97872,     0.97886,     0.97899,     0.97912,     0.97926,     0.97939,     0.97952,     0.97966,     0.97979,     0.97993,     0.98006,     0.98019,     0.98033,     0.98046,      0.9806,     0.98073,     0.98086,       0.981,     0.98113,     0.98127,      0.9814,     0.98153,     0.98167,\n",
       "             0.9818,     0.98193,     0.98207,      0.9822,     0.98234,     0.98247,      0.9826,     0.98274,     0.98287,     0.98301,     0.98314,     0.98327,     0.98341,     0.98354,     0.98364,     0.98369,     0.98375,     0.98381,     0.98387,     0.98393,     0.98399,     0.98404,      0.9841,\n",
       "            0.98416,     0.98422,     0.98428,     0.98434,     0.98439,     0.98445,     0.98451,     0.98457,     0.98463,     0.98469,     0.98474,      0.9848,     0.98486,     0.98492,     0.98498,     0.98504,     0.98509,     0.98515,     0.98521,     0.98527,     0.98533,     0.98539,     0.98544,\n",
       "             0.9855,     0.98556,     0.98562,     0.98568,     0.98574,     0.98579,     0.98585,     0.98591,     0.98597,     0.98603,     0.98609,     0.98614,      0.9862,     0.98626,     0.98632,     0.98638,     0.98644,     0.98649,     0.98655,     0.98661,     0.98667,     0.98673,     0.98678,\n",
       "            0.98684,      0.9869,     0.98696,     0.98702,     0.98708,     0.98713,     0.98719,     0.98725,     0.98731,     0.98737,     0.98743,     0.98748,     0.98754,      0.9876,     0.98766,     0.98772,     0.98778,     0.98783,     0.98789,     0.98795,     0.98801,     0.98807,     0.98813,\n",
       "            0.98818,     0.98824,      0.9883,     0.98836,     0.98842,     0.98848,     0.98853,     0.98859,     0.98865,     0.98871,     0.98877,     0.98883,     0.98888,     0.98894,       0.989,     0.98905,     0.98909,     0.98914,     0.98918,     0.98922,     0.98927,     0.98931,     0.98936,\n",
       "             0.9894,     0.98944,     0.98949,     0.98953,     0.98958,     0.98962,     0.98967,     0.98971,     0.98975,      0.9898,     0.98984,     0.98989,     0.98993,     0.98998,     0.99002,     0.99006,     0.99011,     0.99015,      0.9902,     0.99024,     0.99028,     0.99033,     0.99037,\n",
       "            0.99042,     0.99046,     0.99051,     0.99055,     0.99059,     0.99064,     0.99068,     0.99073,     0.99077,     0.99081,     0.99086,      0.9909,     0.99095,     0.99099,     0.99104,     0.99108,     0.99112,     0.99117,     0.99121,     0.99126,      0.9913,     0.99134,     0.99139,\n",
       "            0.99143,     0.99148,     0.99152,     0.99157,     0.99161,     0.99165,      0.9917,     0.99174,     0.99179,     0.99183,     0.99188,     0.99192,     0.99196,     0.99201,     0.99205,      0.9921,     0.99214,     0.99218,     0.99223,     0.99227,     0.99232,     0.99236,     0.99241,\n",
       "            0.99245,     0.99249,     0.99254,     0.99258,     0.99263,     0.99267,     0.99271,     0.99276,      0.9928,     0.99285,     0.99289,     0.99294,     0.99298,     0.99302,     0.99307,     0.99311,     0.99316,      0.9932,     0.99325,     0.99329,     0.99333,     0.99338,     0.99342,\n",
       "            0.99347,     0.99351,     0.99355,      0.9936,     0.99364,     0.99369,     0.99373,     0.99378,     0.99382,     0.99386,     0.99391,     0.99395,       0.994,     0.99404,     0.99408,     0.99413,     0.99417,     0.99422,     0.99426,     0.99431,     0.99435,     0.99439,     0.99444,\n",
       "            0.99448,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,\n",
       "            0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,     0.99447,\n",
       "            0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,\n",
       "            0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99446,     0.99445,\n",
       "            0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,\n",
       "            0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99444,     0.99444,     0.99444,\n",
       "            0.99444,     0.99444,     0.99444,     0.99444,     0.99444,     0.99444,     0.99444,     0.99444,     0.99444,     0.99444,     0.99443,     0.99443,     0.99443,     0.99443,     0.99443,     0.99443,     0.99443,     0.99443,     0.99443,     0.99443,     0.99443,     0.99443,     0.99442,\n",
       "            0.99442,     0.99442,     0.99442,     0.99442,     0.99442,     0.99442,     0.99442,     0.99442,     0.99442,     0.99442,     0.99441,     0.99441,     0.99441,     0.99441,     0.99441,     0.99441,     0.99441,     0.99441,     0.99441,     0.99441,     0.99441,     0.99441,     0.99441,\n",
       "            0.99441,     0.99441,     0.99441,      0.9944,      0.9944,      0.9944,      0.9944,      0.9944,      0.9944,      0.9944,      0.9944,      0.9944,      0.9944,      0.9944,      0.9944,      0.9944,      0.9944,      0.9944,      0.9944,     0.99439,     0.99439,     0.99439,     0.99439,\n",
       "            0.99439,     0.99439,     0.99439,     0.99439,     0.99439,     0.99439,     0.99439,     0.99439,     0.99439,     0.99439,     0.99439,     0.99439,     0.99439,     0.99438,     0.99438,     0.99438,     0.99438,     0.99438,     0.99438,     0.99438,     0.99438,     0.99438,     0.99437,\n",
       "            0.99437,     0.99437,     0.99437,     0.99437,     0.99437,     0.99437,     0.99436,     0.99436,     0.99436,     0.99436,     0.99436,     0.99436,     0.99435,     0.99435,     0.99435,     0.99439,     0.99442,     0.99446,      0.9945,     0.99454,     0.99458,     0.99462,     0.99466,\n",
       "             0.9947,     0.99474,     0.99478,     0.99481,     0.99485,     0.99489,     0.99493,     0.99497,     0.99501,     0.99505,     0.99509,     0.99513,     0.99517,     0.99521,     0.99524,     0.99528,     0.99532,     0.99536,      0.9954,     0.99544,     0.99548,     0.99552,     0.99556,\n",
       "             0.9956,     0.99564,     0.99567,     0.99571,     0.99575,     0.99579,     0.99583,     0.99587,     0.99591,     0.99595,     0.99599,     0.99603,     0.99606,      0.9961,     0.99614,     0.99618,     0.99622,     0.99626,      0.9963,     0.99634,     0.99638,     0.99642,     0.99646,\n",
       "            0.99649,     0.99653,     0.99657,     0.99661,     0.99665,     0.99669,     0.99673,     0.99677,     0.99681,     0.99685,     0.99688,     0.99692,     0.99696,       0.997,     0.99704,     0.99708,     0.99712,     0.99716,      0.9972,     0.99724,     0.99728,     0.99731,     0.99735,\n",
       "            0.99739,     0.99743,     0.99747,     0.99751,     0.99755,     0.99759,     0.99763,     0.99767,      0.9977,     0.99774,     0.99778,     0.99782,     0.99786,      0.9979,     0.99794,     0.99798,     0.99802,     0.99806,      0.9981,     0.99813,     0.99817,     0.99821,     0.99825,\n",
       "            0.99829,     0.99833,     0.99837,     0.99841,     0.99845,     0.99849,     0.99853,     0.99856,      0.9986,     0.99864,     0.99868,     0.99872,     0.99876,      0.9988,     0.99884,     0.99888,     0.99892,     0.99895,     0.99899,     0.99903,     0.99907,     0.99911,     0.99915,\n",
       "            0.99919,     0.99923,     0.99927,     0.99931,     0.99935,     0.99938,     0.99942,     0.99946,      0.9995,     0.99954,     0.99958,     0.99962,     0.99966,      0.9997,     0.99974,     0.99977,     0.99981,     0.99985,     0.99989,     0.99993,     0.99997,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "            0.99999,     0.99995,     0.99991,     0.99987,     0.99983,     0.99979,     0.99975,     0.99971,     0.99967,     0.99963,     0.99959,     0.99955,     0.99951,     0.99947,     0.99943,     0.99939,     0.99935,     0.99931,     0.99927,     0.99923,     0.99919,     0.99915,     0.99911,\n",
       "            0.99906,     0.99902,     0.99898,     0.99894,      0.9989,     0.99886,     0.99882,     0.99878,     0.99874,      0.9987,     0.99866,     0.99862,     0.99858,     0.99854,      0.9985,     0.99846,     0.99842,     0.99838,     0.99834,      0.9983,     0.99826,     0.99822,     0.99818,\n",
       "            0.99814,      0.9981,     0.99806,     0.99801,     0.99797,     0.99793,     0.99789,     0.99785,     0.99781,     0.99777,     0.99773,     0.99769,     0.99765,     0.99761,     0.99757,     0.99753,     0.99749,     0.99745,     0.99741,     0.99737,     0.99733,     0.99729,     0.99725,\n",
       "            0.99721,     0.99717,     0.99713,     0.99709,     0.99705,     0.99701,     0.99696,     0.99692,     0.99688,     0.99684,      0.9968,     0.99676,     0.99672,     0.99668,     0.99664,      0.9966,     0.99656,     0.99652,     0.99648,     0.99644,      0.9964,     0.99636,     0.99632,\n",
       "            0.99628,     0.99624,      0.9962,     0.99616,     0.99612,     0.99608,     0.99604,       0.996,     0.99596,     0.99592,     0.99587,     0.99583,     0.99579,     0.99575,     0.99571,     0.99567,     0.99563,     0.99559,     0.99555,     0.99551,     0.99547,     0.99543,     0.99539,\n",
       "            0.99535,     0.99531,     0.99527,     0.99523,     0.99519,     0.99515,     0.99511,     0.99507,     0.99503,     0.99499,     0.99495,     0.99491,     0.99487,     0.99482,     0.99478,     0.99474,      0.9947,     0.99466,     0.99462,     0.99458,     0.99454,      0.9945,     0.99446,\n",
       "            0.99435,     0.99419,     0.99403,     0.99387,     0.99371,     0.99355,     0.99339,     0.99323,     0.99307,     0.99291,     0.99275,     0.99259,     0.99243,     0.99227,     0.99211,     0.99195,     0.99179,     0.99163,     0.99146,      0.9913,     0.99114,     0.99098,     0.99082,\n",
       "            0.99066,      0.9905,     0.99034,     0.99018,     0.99002,     0.98986,      0.9897,     0.98954,     0.98938,     0.98922,     0.98906,      0.9889,     0.98879,     0.98868,     0.98858,     0.98847,     0.98837,     0.98826,     0.98815,     0.98805,     0.98794,     0.98784,     0.98773,\n",
       "            0.98763,     0.98752,     0.98741,     0.98731,      0.9872,      0.9871,     0.98699,     0.98688,     0.98678,     0.98667,     0.98657,     0.98646,     0.98636,     0.98625,     0.98614,     0.98604,     0.98593,     0.98583,     0.98572,     0.98561,     0.98551,      0.9854,      0.9853,\n",
       "            0.98519,     0.98509,     0.98498,     0.98487,     0.98477,     0.98466,     0.98456,     0.98445,     0.98434,     0.98424,     0.98413,     0.98403,     0.98392,     0.98382,     0.98371,      0.9836,      0.9835,     0.98339,     0.98321,     0.98292,     0.98264,     0.98235,     0.98207,\n",
       "            0.98179,      0.9815,     0.98122,     0.98093,     0.98065,     0.98036,     0.98008,      0.9798,     0.97951,     0.97923,     0.97894,     0.97866,     0.97838,     0.97809,     0.97781,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,\n",
       "            0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,\n",
       "            0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,\n",
       "            0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,\n",
       "            0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,\n",
       "            0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,\n",
       "            0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97778,     0.97762,     0.97696,\n",
       "            0.97631,     0.97565,     0.97499,     0.97433,     0.97367,     0.97302,     0.97236,     0.96649,     0.96588,     0.96526,     0.96465,     0.96403,     0.96342,      0.9628,     0.96218,     0.96157,      0.9583,     0.95343,      0.9506,     0.94381,     0.93839,     0.93761,     0.93684,\n",
       "            0.93607,     0.93529,     0.93452,     0.93374,     0.93293,     0.93206,     0.93119,     0.93032,     0.92945,     0.92858,     0.92757,     0.92479,     0.92211,     0.92073,     0.91935,     0.91797,     0.91653,     0.91418,     0.91182,     0.91068,     0.91007,     0.90946,     0.90884,\n",
       "            0.90823,     0.90762,     0.90701,     0.90639,     0.90578,      0.9037,     0.90075,     0.89906,      0.8978,     0.89654,     0.89529,     0.89367,     0.89131,     0.88896,     0.88653,      0.8841,     0.88175,     0.87944,      0.8766,     0.87237,     0.86925,     0.86538,     0.85923,\n",
       "             0.8544,      0.8422,     0.81675,     0.80149,     0.78322,     0.78018,      0.7761,     0.76343,     0.73845,     0.72234,      0.7053,     0.70161,     0.67979,     0.65833,     0.63567,     0.62132,     0.61237,     0.57911,     0.55699,     0.55135,     0.54635,     0.52833,     0.51471,\n",
       "            0.49967,     0.48196,     0.47228,     0.46294,     0.45841,     0.45354,     0.43914,      0.4251,     0.41375,     0.39704,     0.39038,     0.37558,     0.34068,     0.31266,     0.29841,     0.27915,     0.25909,     0.25199,     0.22379,     0.20255,     0.18949,     0.17479,     0.16223,\n",
       "             0.1563,     0.13094,     0.11279,     0.10943,     0.10732,     0.10373,    0.088291,    0.085249,    0.081542,    0.076684,    0.066656,     0.06449,    0.062324,    0.048956,     0.03883,    0.037658,    0.036485,    0.035312,     0.03414,    0.026043,    0.021472,     0.02064,    0.019808,\n",
       "           0.018976,    0.018144,    0.017312,    0.015687,    0.011313,    0.010818,    0.010511,    0.010204,   0.0098973,   0.0095903,   0.0092833,   0.0089763,   0.0086693,   0.0083623,   0.0080553,   0.0077482,   0.0074412,   0.0071342,   0.0068272,   0.0065202,   0.0062132,   0.0059062,   0.0055992,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.8230952179664279\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.80401])\n",
       "names: {0: 'license_plate'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.9944746557135659, 'metrics/recall(B)': 0.9999126841554167, 'metrics/mAP50(B)': 0.9948895027624309, 'metrics/mAP50-95(B)': 0.8040069641002054, 'fitness': 0.8230952179664279}\n",
       "save_dir: WindowsPath('runs/detect/train4')\n",
       "speed: {'preprocess': 0.7468369272020128, 'inference': 35.68201329973009, 'loss': 0.0, 'postprocess': 0.20425452126397026}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")  # Load YOLO model\n",
    "model.train(data=\"data-l.yaml\", epochs=50, imgsz=640, batch=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1000.jpg: 448x640 1 license_plate, 141.9ms\n",
      "image 2/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1001.jpg: 640x384 1 license_plate, 62.4ms\n",
      "image 3/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1002.jpg: 640x480 1 license_plate, 66.9ms\n",
      "image 4/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1003.jpg: 384x640 1 license_plate, 50.3ms\n",
      "image 5/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1004.jpg: 640x384 1 license_plate, 40.8ms\n",
      "image 6/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1005.jpg: 640x384 1 license_plate, 31.4ms\n",
      "image 7/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1006.jpg: 640x480 1 license_plate, 35.3ms\n",
      "image 8/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1007.jpg: 640x384 1 license_plate, 28.0ms\n",
      "image 9/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1008.jpg: 384x640 1 license_plate, 31.6ms\n",
      "image 10/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1009.jpg: 384x640 1 license_plate, 34.7ms\n",
      "image 11/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1010.jpg: 640x384 1 license_plate, 30.9ms\n",
      "image 12/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1011.jpg: 640x384 1 license_plate, 31.0ms\n",
      "image 13/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1012.jpg: 480x640 1 license_plate, 50.9ms\n",
      "image 14/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1013.jpg: 640x480 1 license_plate, 39.7ms\n",
      "image 15/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1014.jpg: 480x640 1 license_plate, 42.5ms\n",
      "image 16/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1015.jpg: 480x640 1 license_plate, 35.3ms\n",
      "image 17/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1016.jpg: 480x640 1 license_plate, 27.4ms\n",
      "image 18/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1017.jpg: 384x640 1 license_plate, 30.3ms\n",
      "image 19/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1018.jpg: 480x640 1 license_plate, 39.5ms\n",
      "image 20/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1019.jpg: 384x640 1 license_plate, 27.1ms\n",
      "image 21/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1020.jpg: 640x480 1 license_plate, 34.3ms\n",
      "image 22/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1021.jpg: 640x384 1 license_plate, 31.9ms\n",
      "image 23/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1022.jpg: 384x640 1 license_plate, 31.2ms\n",
      "image 24/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1023.jpg: 384x640 1 license_plate, 35.4ms\n",
      "image 25/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1024.jpg: 384x640 1 license_plate, 34.5ms\n",
      "image 26/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1025.jpg: 640x480 1 license_plate, 35.6ms\n",
      "image 27/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1026.jpg: 640x480 1 license_plate, 35.7ms\n",
      "image 28/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1027.jpg: 384x640 1 license_plate, 34.8ms\n",
      "image 29/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1028.jpg: 640x480 1 license_plate, 42.7ms\n",
      "image 30/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1029.jpg: 384x640 1 license_plate, 32.3ms\n",
      "image 31/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1030.jpg: 384x640 1 license_plate, 31.9ms\n",
      "image 32/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1031.jpg: 480x640 1 license_plate, 34.8ms\n",
      "image 33/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1032.jpg: 640x480 2 license_plates, 33.4ms\n",
      "image 34/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1033.jpg: 480x640 2 license_plates, 42.3ms\n",
      "image 35/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1034.jpg: 640x480 1 license_plate, 32.2ms\n",
      "image 36/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1035.jpg: 640x480 1 license_plate, 37.8ms\n",
      "image 37/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1036.jpg: 640x480 1 license_plate, 34.3ms\n",
      "image 38/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1037.jpg: 384x640 1 license_plate, 30.7ms\n",
      "image 39/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1038.jpg: 640x384 1 license_plate, 42.8ms\n",
      "image 40/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1039.jpg: 384x640 1 license_plate, 37.3ms\n",
      "image 41/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1040.jpg: 640x480 1 license_plate, 36.6ms\n",
      "image 42/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1041.jpg: 384x640 1 license_plate, 41.7ms\n",
      "image 43/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1042.jpg: 384x640 1 license_plate, 40.1ms\n",
      "image 44/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1043.jpg: 640x544 1 license_plate, 68.5ms\n",
      "image 45/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1044.jpg: 640x480 1 license_plate, 35.3ms\n",
      "image 46/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1045.jpg: 480x640 1 license_plate, 38.9ms\n",
      "image 47/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1046.jpg: 640x480 1 license_plate, 36.0ms\n",
      "image 48/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1047.jpg: 480x640 1 license_plate, 42.2ms\n",
      "image 49/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1048.jpg: 480x640 1 license_plate, 39.4ms\n",
      "image 50/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1049.jpg: 640x480 1 license_plate, 38.4ms\n",
      "image 51/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1050.jpg: 512x640 1 license_plate, 99.4ms\n",
      "image 52/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1051.jpg: 416x640 1 license_plate, 90.5ms\n",
      "image 53/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1052.jpg: 384x640 2 license_plates, 37.5ms\n",
      "image 54/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1053.jpg: 640x480 1 license_plate, 36.0ms\n",
      "image 55/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1054.jpg: 384x640 1 license_plate, 37.4ms\n",
      "image 56/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1055.jpg: 640x384 1 license_plate, 37.2ms\n",
      "image 57/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1056.jpg: 640x480 1 license_plate, 33.8ms\n",
      "image 58/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1057.jpg: 640x544 1 license_plate, 41.6ms\n",
      "image 59/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1058.jpg: 384x640 1 license_plate, 41.2ms\n",
      "image 60/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1059.jpg: 384x640 1 license_plate, 44.1ms\n",
      "image 61/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1060.jpg: 640x416 1 license_plate, 59.7ms\n",
      "image 62/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1061.jpg: 640x384 1 license_plate, 41.9ms\n",
      "image 63/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1062.jpg: 384x640 1 license_plate, 31.7ms\n",
      "image 64/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1063.jpg: 640x480 1 license_plate, 36.2ms\n",
      "image 65/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1064.jpg: 640x384 1 license_plate, 35.5ms\n",
      "image 66/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1065.jpg: 640x544 1 license_plate, 33.7ms\n",
      "image 67/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1066.jpg: 640x544 1 license_plate, 42.4ms\n",
      "image 68/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1067.jpg: 640x480 1 license_plate, 31.7ms\n",
      "image 69/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1068.jpg: 480x640 1 license_plate, 38.5ms\n",
      "image 70/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1069.jpg: 384x640 1 license_plate, 44.1ms\n",
      "image 71/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1070.jpg: 640x384 1 license_plate, 27.3ms\n",
      "image 72/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1071.jpg: 640x480 1 license_plate, 29.5ms\n",
      "image 73/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1072.jpg: 480x640 1 license_plate, 36.2ms\n",
      "image 74/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1073.jpg: 448x640 1 license_plate, 36.3ms\n",
      "image 75/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1074.jpg: 480x640 1 license_plate, 39.5ms\n",
      "image 76/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1075.jpg: 640x480 1 license_plate, 35.6ms\n",
      "image 77/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1076.jpg: 640x480 1 license_plate, 44.4ms\n",
      "image 78/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1077.jpg: 480x640 1 license_plate, 39.7ms\n",
      "image 79/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1078.jpg: 640x480 1 license_plate, 44.1ms\n",
      "image 80/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1079.jpg: 640x384 1 license_plate, 37.9ms\n",
      "image 81/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1080.jpg: 640x480 1 license_plate, 38.2ms\n",
      "image 82/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1081.jpg: 640x480 1 license_plate, 41.7ms\n",
      "image 83/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1082.jpg: 640x480 1 license_plate, 33.9ms\n",
      "image 84/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1083.jpg: 640x480 1 license_plate, 33.5ms\n",
      "image 85/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1084.jpg: 480x640 1 license_plate, 36.9ms\n",
      "image 86/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1085.jpg: 640x480 1 license_plate, 35.9ms\n",
      "image 87/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1086.jpg: 384x640 1 license_plate, 34.0ms\n",
      "image 88/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1087.jpg: 640x512 1 license_plate, 63.7ms\n",
      "image 89/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1088.jpg: 384x640 1 license_plate, 33.6ms\n",
      "image 90/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1089.jpg: 384x640 1 license_plate, 31.1ms\n",
      "image 91/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1090.jpg: 640x480 1 license_plate, 34.6ms\n",
      "image 92/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1091.jpg: 384x640 1 license_plate, 42.0ms\n",
      "image 93/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1092.jpg: 384x640 1 license_plate, 41.9ms\n",
      "image 94/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1093.jpg: 640x384 1 license_plate, 35.3ms\n",
      "image 95/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1094.jpg: 480x640 1 license_plate, 45.1ms\n",
      "image 96/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1095.jpg: 512x640 1 license_plate, 48.2ms\n",
      "image 97/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1096.jpg: 480x640 1 license_plate, 31.6ms\n",
      "image 98/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1098.jpg: 384x640 1 license_plate, 28.5ms\n",
      "image 99/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1099.jpg: 480x640 1 license_plate, 40.6ms\n",
      "image 100/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1100.jpg: 384x640 1 license_plate, 36.7ms\n",
      "image 101/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1101.jpg: 480x640 1 license_plate, 35.1ms\n",
      "image 102/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1102.jpg: 640x480 1 license_plate, 55.5ms\n",
      "image 103/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1103.jpg: 480x640 1 license_plate, 36.2ms\n",
      "image 104/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1104.jpg: 640x384 1 license_plate, 33.4ms\n",
      "image 105/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1105.jpg: 640x480 1 license_plate, 37.0ms\n",
      "image 106/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1106.jpg: 640x480 1 license_plate, 37.5ms\n",
      "image 107/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1107.jpg: 480x640 1 license_plate, 30.1ms\n",
      "image 108/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1108.jpg: 480x640 1 license_plate, 40.9ms\n",
      "image 109/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1109.jpg: 640x384 1 license_plate, 33.2ms\n",
      "image 110/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1110.jpg: 640x480 1 license_plate, 41.9ms\n",
      "image 111/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1111.jpg: 640x384 1 license_plate, 32.9ms\n",
      "image 112/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1112.jpg: 640x480 1 license_plate, 40.1ms\n",
      "image 113/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\1113.jpg: 384x640 1 license_plate, 29.3ms\n",
      "image 114/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\901.jpg: 640x480 1 license_plate, 40.2ms\n",
      "image 115/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\902.jpg: 384x640 1 license_plate, 34.4ms\n",
      "image 116/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\903.jpg: 640x480 1 license_plate, 34.1ms\n",
      "image 117/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\904.jpg: 384x640 1 license_plate, 35.6ms\n",
      "image 118/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\905.jpg: 640x480 1 license_plate, 33.9ms\n",
      "image 119/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\906.jpg: 384x640 1 license_plate, 34.7ms\n",
      "image 120/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\907.jpg: 640x480 1 license_plate, 36.8ms\n",
      "image 121/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\908.jpg: 384x640 1 license_plate, 28.8ms\n",
      "image 122/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\909.jpg: 640x480 1 license_plate, 33.5ms\n",
      "image 123/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\910.jpg: 384x640 1 license_plate, 33.5ms\n",
      "image 124/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\911.jpg: 640x480 1 license_plate, 36.3ms\n",
      "image 125/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\912.jpg: 384x640 1 license_plate, 31.6ms\n",
      "image 126/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\913.jpg: 480x640 1 license_plate, 31.2ms\n",
      "image 127/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\914.jpg: 384x640 1 license_plate, 33.7ms\n",
      "image 128/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\915.jpg: 384x640 1 license_plate, 25.0ms\n",
      "image 129/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\917.jpg: 480x640 1 license_plate, 42.1ms\n",
      "image 130/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\918.jpg: 480x640 1 license_plate, 33.7ms\n",
      "image 131/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\919.jpg: 384x640 1 license_plate, 25.2ms\n",
      "image 132/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\920.jpg: 384x640 1 license_plate, 31.3ms\n",
      "image 133/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\921.jpg: 480x640 2 license_plates, 33.7ms\n",
      "image 134/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\922.jpg: 640x640 1 license_plate, 74.0ms\n",
      "image 135/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\923.jpg: 640x480 1 license_plate, 33.3ms\n",
      "image 136/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\924.jpg: 480x640 1 license_plate, 30.4ms\n",
      "image 137/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\925.jpg: 640x384 1 license_plate, 33.6ms\n",
      "image 138/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\926.jpg: 640x512 1 license_plate, 41.8ms\n",
      "image 139/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\927.jpg: 640x480 1 license_plate, 41.9ms\n",
      "image 140/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\928.jpg: 480x640 1 license_plate, 33.6ms\n",
      "image 141/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\929.jpg: 480x640 1 license_plate, 36.1ms\n",
      "image 142/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\930.jpg: 448x640 1 license_plate, 35.5ms\n",
      "image 143/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\931.jpg: 480x640 1 license_plate, 36.0ms\n",
      "image 144/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\932.jpg: 640x480 1 license_plate, 33.5ms\n",
      "image 145/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\933.jpg: 640x480 1 license_plate, 34.7ms\n",
      "image 146/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\934.jpg: 384x640 1 license_plate, 33.6ms\n",
      "image 147/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\935.jpg: 640x480 1 license_plate, 33.7ms\n",
      "image 148/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\936.jpg: 384x640 1 license_plate, 33.2ms\n",
      "image 149/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\937.jpg: 480x640 1 license_plate, 32.9ms\n",
      "image 150/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\938.jpg: 640x576 1 license_plate, 67.0ms\n",
      "image 151/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\939.jpg: 480x640 1 license_plate, 42.1ms\n",
      "image 152/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\940.jpg: 448x640 1 license_plate, 25.0ms\n",
      "image 153/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\941.jpg: 480x640 1 license_plate, 42.0ms\n",
      "image 154/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\942.jpg: 384x640 1 license_plate, 31.6ms\n",
      "image 155/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\943.jpg: 640x576 1 license_plate, 41.9ms\n",
      "image 156/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\944.jpg: 640x480 1 license_plate, 32.2ms\n",
      "image 157/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\945.jpg: 384x640 1 license_plate, 33.9ms\n",
      "image 158/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\946.jpg: 480x640 1 license_plate, 33.1ms\n",
      "image 159/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\947.jpg: 640x384 1 license_plate, 37.9ms\n",
      "image 160/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\948.jpg: 384x640 1 license_plate, 33.5ms\n",
      "image 161/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\949.jpg: 640x384 1 license_plate, 33.1ms\n",
      "image 162/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\950.jpg: 480x640 1 license_plate, 34.4ms\n",
      "image 163/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\951.jpg: 384x640 1 license_plate, 33.0ms\n",
      "image 164/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\952.jpg: 384x640 1 license_plate, 48.0ms\n",
      "image 165/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\953.jpg: 480x640 1 license_plate, 33.2ms\n",
      "image 166/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\954.jpg: 384x640 1 license_plate, 31.8ms\n",
      "image 167/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\955.jpg: 640x384 1 license_plate, 34.6ms\n",
      "image 168/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\956.jpg: 384x640 1 license_plate, 33.6ms\n",
      "image 169/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\957.jpg: 384x640 1 license_plate, 25.0ms\n",
      "image 170/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\958.jpg: 384x640 1 license_plate, 25.6ms\n",
      "image 171/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\959.jpg: 640x384 1 license_plate, 36.5ms\n",
      "image 172/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\960.jpg: 416x640 1 license_plate, 35.3ms\n",
      "image 173/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\961.jpg: 640x480 1 license_plate, 34.4ms\n",
      "image 174/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\962.jpg: 384x640 1 license_plate, 35.8ms\n",
      "image 175/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\963.jpg: 384x640 1 license_plate, 30.2ms\n",
      "image 176/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\964.jpg: 480x640 1 license_plate, 35.5ms\n",
      "image 177/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\965.jpg: 640x480 1 license_plate, 33.9ms\n",
      "image 178/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\966.jpg: 480x640 1 license_plate, 33.8ms\n",
      "image 179/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\967.jpg: 640x480 1 license_plate, 29.7ms\n",
      "image 180/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\968.jpg: 640x480 1 license_plate, 34.3ms\n",
      "image 181/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\969.jpg: 640x480 1 license_plate, 34.2ms\n",
      "image 182/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\970.jpg: 384x640 1 license_plate, 32.6ms\n",
      "image 183/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\971.jpg: 480x640 1 license_plate, 37.2ms\n",
      "image 184/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\972.jpg: 480x640 1 license_plate, 33.5ms\n",
      "image 185/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\973.jpg: 640x480 1 license_plate, 42.1ms\n",
      "image 186/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\974.jpg: 448x640 1 license_plate, 33.4ms\n",
      "image 187/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\975.jpg: 640x384 1 license_plate, 33.3ms\n",
      "image 188/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\976.jpg: 480x640 1 license_plate, 41.9ms\n",
      "image 189/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\977.jpg: 480x640 1 license_plate, 33.8ms\n",
      "image 190/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\978.jpg: 384x640 1 license_plate, 33.5ms\n",
      "image 191/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\979.jpg: 480x640 1 license_plate, 35.0ms\n",
      "image 192/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\981.jpg: 448x640 1 license_plate, 33.6ms\n",
      "image 193/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\982.jpg: 640x384 1 license_plate, 33.8ms\n",
      "image 194/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\983.jpg: 480x640 1 license_plate, 35.4ms\n",
      "image 195/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\984.jpg: 480x640 1 license_plate, 40.5ms\n",
      "image 196/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\985.jpg: 640x480 1 license_plate, 35.1ms\n",
      "image 197/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\986.jpg: 480x640 1 license_plate, 33.6ms\n",
      "image 198/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\987.jpg: 480x640 1 license_plate, 31.3ms\n",
      "image 199/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\988.jpg: 640x480 1 license_plate, 33.9ms\n",
      "image 200/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\989.jpg: 384x640 1 license_plate, 29.7ms\n",
      "image 201/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\990.jpg: 640x480 1 license_plate, 39.2ms\n",
      "image 202/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\991.jpg: 480x640 1 license_plate, 32.8ms\n",
      "image 203/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\992.jpg: 640x480 1 license_plate, 41.3ms\n",
      "image 204/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\993.jpg: 640x384 1 license_plate, 32.9ms\n",
      "image 205/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\994.jpg: 640x480 1 license_plate, 37.4ms\n",
      "image 206/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\995.jpg: 480x640 1 license_plate, 34.1ms\n",
      "image 207/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\996.jpg: 480x640 1 license_plate, 33.4ms\n",
      "image 208/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\997.jpg: 640x480 1 license_plate, 34.5ms\n",
      "image 209/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\998.jpg: 640x480 1 license_plate, 39.4ms\n",
      "image 210/210 d:\\Projects\\DATA SCIENTIST_ASSIGNMENT-20250318T115327Z-001\\data_detection\\test\\999.jpg: 384x640 1 license_plate, 31.8ms\n",
      "Speed: 1.5ms preprocess, 37.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"runs/detect/train4/weights/best.pt\")\n",
    "results = model.predict(source=\"data_detection/test\", save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.6.0+cpu)\n",
      "Requirement already satisfied: torchvision in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.21.0+cpu)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.6.0+cpu)\n",
      "Requirement already satisfied: numpy in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: pillow in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: pytorch-lightning in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.0.post0)\n",
      "Requirement already satisfied: Levenshtein in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.27.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (70.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-lightning) (4.66.4)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-lightning) (6.0.1)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-lightning) (1.6.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-lightning) (24.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-lightning) (0.11.9)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Levenshtein) (3.12.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\anand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio numpy opencv-python pillow pytorch-lightning Levenshtein\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# Define character mapping (A-Z, 0-9)\n",
    "characters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "char_to_index = {char: idx + 1 for idx, char in enumerate(characters)}  # 1-based index\n",
    "char_to_index[\"PAD\"] = 0  # Padding character\n",
    "\n",
    "# Define max sequence length (maximum license plate length)\n",
    "MAX_LEN = 10\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((32, 128)),  # Resize images to standard size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "class LicensePlateDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_folder):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_folder = image_folder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_name = os.path.join(self.image_folder, self.data.iloc[idx, 0])\n",
    "        image = Image.open(img_name).convert('L')  # Convert to grayscale\n",
    "        image = transform(image)\n",
    "\n",
    "        # Encode text label\n",
    "        text = self.data.iloc[idx, 1].upper()\n",
    "        label = [char_to_index[char] for char in text if char in char_to_index]\n",
    "\n",
    "        # Pad label to MAX_LEN\n",
    "        label += [char_to_index[\"PAD\"]] * (MAX_LEN - len(label))\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Define dataset paths\n",
    "train_csv = \"Licplatesrecognition_train.csv\"\n",
    "train_img_folder = \"license_plates_recognition_train\"\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = LicensePlateDataset(train_csv, train_img_folder)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CRNN, self).__init__()\n",
    "\n",
    "        # Feature extractor (CNN)\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,1)),  # Maintain width for sequence processing\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,1)),\n",
    "        )\n",
    "\n",
    "        # LSTM for sequence modeling\n",
    "        self.lstm = nn.LSTM(512, 256, bidirectional=True, num_layers=2, batch_first=True)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)  # CNN features -> (batch, channels, height, width)\n",
    "        \n",
    "        x = x.view(x.size(0), x.size(1), -1)  # Flatten height\n",
    "  # Ensure height is removed, now (batch, channels, width)\n",
    "        \n",
    "        x = x.permute(0, 2, 1)  # Correct order for LSTM (batch, sequence, features)\n",
    "\n",
    "        x, _ = self.lstm(x)  # LSTM for sequence learning\n",
    "        \n",
    "        x = self.fc(x)  # Fully connected output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.4026\n",
      "Epoch [2/10], Loss: 3.0824\n",
      "Epoch [3/10], Loss: 2.5619\n",
      "Epoch [4/10], Loss: 2.6114\n",
      "Epoch [5/10], Loss: 2.5970\n",
      "Epoch [6/10], Loss: 2.5884\n",
      "Epoch [7/10], Loss: 2.5755\n",
      "Epoch [8/10], Loss: 2.5662\n",
      "Epoch [9/10], Loss: 2.5486\n",
      "Epoch [10/10], Loss: 2.5266\n",
      "Training complete! Model saved.\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define model, optimizer, and loss\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CRNN(num_classes=len(char_to_index)).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CTCLoss(blank=0)  # Use padding as blank character\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Compute loss\n",
    "        input_lengths = torch.full((outputs.size(0),), outputs.size(1), dtype=torch.long).to(device)\n",
    "        target_lengths = torch.sum(labels != 0, dim=1).to(device)  # Non-zero lengths\n",
    "\n",
    "        loss = criterion(outputs.permute(1, 0, 2), labels, input_lengths, target_lengths)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"crnn_best.pth\")\n",
    "print(\"Training complete! Model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 1000.jpg, OCR Prediction: \n",
      "Image: 1001.jpg, OCR Prediction: \n",
      "Image: 1002.jpg, OCR Prediction: \n",
      "Image: 1003.jpg, OCR Prediction: \n",
      "Image: 1004.jpg, OCR Prediction: \n",
      "Image: 1005.jpg, OCR Prediction: \n",
      "Image: 1006.jpg, OCR Prediction: \n",
      "Image: 1007.jpg, OCR Prediction: \n",
      "Image: 1008.jpg, OCR Prediction: \n",
      "Image: 1009.jpg, OCR Prediction: \n",
      "Image: 1010.jpg, OCR Prediction: \n",
      "Image: 1011.jpg, OCR Prediction: \n",
      "Image: 1012.jpg, OCR Prediction: \n",
      "Image: 1013.jpg, OCR Prediction: \n",
      "Image: 1014.jpg, OCR Prediction: \n",
      "Image: 1015.jpg, OCR Prediction: \n",
      "Image: 1016.jpg, OCR Prediction: \n",
      "Image: 1017.jpg, OCR Prediction: \n",
      "Image: 1018.jpg, OCR Prediction: \n",
      "Image: 1019.jpg, OCR Prediction: \n",
      "Image: 1020.jpg, OCR Prediction: \n",
      "Image: 1021.jpg, OCR Prediction: \n",
      "Image: 1022.jpg, OCR Prediction: \n",
      "Image: 1023.jpg, OCR Prediction: \n",
      "Image: 1024.jpg, OCR Prediction: \n",
      "Image: 1025.jpg, OCR Prediction: \n",
      "Image: 1026.jpg, OCR Prediction: \n",
      "Image: 1027.jpg, OCR Prediction: \n",
      "Image: 1028.jpg, OCR Prediction: \n",
      "Image: 1029.jpg, OCR Prediction: \n",
      "Image: 1030.jpg, OCR Prediction: \n",
      "Image: 1031.jpg, OCR Prediction: \n",
      "Image: 1032.jpg, OCR Prediction: \n",
      "Image: 1033.jpg, OCR Prediction: \n",
      "Image: 1034.jpg, OCR Prediction: \n",
      "Image: 1035.jpg, OCR Prediction: \n",
      "Image: 1036.jpg, OCR Prediction: \n",
      "Image: 1037.jpg, OCR Prediction: \n",
      "Image: 1038.jpg, OCR Prediction: \n",
      "Image: 1039.jpg, OCR Prediction: \n",
      "Image: 1040.jpg, OCR Prediction: \n",
      "Image: 1041.jpg, OCR Prediction: \n",
      "Image: 1042.jpg, OCR Prediction: \n",
      "Image: 1043.jpg, OCR Prediction: \n",
      "Image: 1044.jpg, OCR Prediction: \n",
      "Image: 1045.jpg, OCR Prediction: \n",
      "Image: 1046.jpg, OCR Prediction: \n",
      "Image: 1047.jpg, OCR Prediction: \n",
      "Image: 1048.jpg, OCR Prediction: \n",
      "Image: 1049.jpg, OCR Prediction: \n",
      "Image: 1050.jpg, OCR Prediction: \n",
      "Image: 1051.jpg, OCR Prediction: \n",
      "Image: 1052.jpg, OCR Prediction: \n",
      "Image: 1053.jpg, OCR Prediction: \n",
      "Image: 1054.jpg, OCR Prediction: \n",
      "Image: 1055.jpg, OCR Prediction: \n",
      "Image: 1056.jpg, OCR Prediction: \n",
      "Image: 1057.jpg, OCR Prediction: \n",
      "Image: 1058.jpg, OCR Prediction: \n",
      "Image: 1059.jpg, OCR Prediction: \n",
      "Image: 1060.jpg, OCR Prediction: \n",
      "Image: 1061.jpg, OCR Prediction: \n",
      "Image: 1062.jpg, OCR Prediction: \n",
      "Image: 1063.jpg, OCR Prediction: \n",
      "Image: 1064.jpg, OCR Prediction: \n",
      "Image: 1065.jpg, OCR Prediction: \n",
      "Image: 1066.jpg, OCR Prediction: \n",
      "Image: 1067.jpg, OCR Prediction: \n",
      "Image: 1068.jpg, OCR Prediction: \n",
      "Image: 1069.jpg, OCR Prediction: \n",
      "Image: 1070.jpg, OCR Prediction: \n",
      "Image: 1071.jpg, OCR Prediction: \n",
      "Image: 1072.jpg, OCR Prediction: \n",
      "Image: 1073.jpg, OCR Prediction: \n",
      "Image: 1074.jpg, OCR Prediction: \n",
      "Image: 1075.jpg, OCR Prediction: \n",
      "Image: 1076.jpg, OCR Prediction: \n",
      "Image: 1077.jpg, OCR Prediction: \n",
      "Image: 1078.jpg, OCR Prediction: \n",
      "Image: 1079.jpg, OCR Prediction: \n",
      "Image: 1080.jpg, OCR Prediction: \n",
      "Image: 1081.jpg, OCR Prediction: \n",
      "Image: 1082.jpg, OCR Prediction: \n",
      "Image: 1083.jpg, OCR Prediction: \n",
      "Image: 1084.jpg, OCR Prediction: \n",
      "Image: 1085.jpg, OCR Prediction: \n",
      "Image: 1086.jpg, OCR Prediction: \n",
      "Image: 1087.jpg, OCR Prediction: \n",
      "Image: 1088.jpg, OCR Prediction: \n",
      "Image: 1089.jpg, OCR Prediction: \n",
      "Image: 1090.jpg, OCR Prediction: \n",
      "Image: 1091.jpg, OCR Prediction: \n",
      "Image: 1092.jpg, OCR Prediction: \n",
      "Image: 1093.jpg, OCR Prediction: \n",
      "Image: 1094.jpg, OCR Prediction: \n",
      "Image: 1095.jpg, OCR Prediction: \n",
      "Image: 1096.jpg, OCR Prediction: \n",
      "Image: 1098.jpg, OCR Prediction: \n",
      "Image: 1099.jpg, OCR Prediction: \n",
      "Image: 1100.jpg, OCR Prediction: \n",
      "Image: 1101.jpg, OCR Prediction: \n",
      "Image: 1102.jpg, OCR Prediction: \n",
      "Image: 1103.jpg, OCR Prediction: \n",
      "Image: 1104.jpg, OCR Prediction: \n",
      "Image: 1105.jpg, OCR Prediction: \n",
      "Image: 1106.jpg, OCR Prediction: \n",
      "Image: 1107.jpg, OCR Prediction: \n",
      "Image: 1108.jpg, OCR Prediction: \n",
      "Image: 1109.jpg, OCR Prediction: \n",
      "Image: 1110.jpg, OCR Prediction: \n",
      "Image: 1111.jpg, OCR Prediction: \n",
      "Image: 1112.jpg, OCR Prediction: \n",
      "Image: 1113.jpg, OCR Prediction: \n",
      "Image: 901.jpg, OCR Prediction: \n",
      "Image: 902.jpg, OCR Prediction: \n",
      "Image: 903.jpg, OCR Prediction: \n",
      "Image: 904.jpg, OCR Prediction: \n",
      "Image: 905.jpg, OCR Prediction: \n",
      "Image: 906.jpg, OCR Prediction: \n",
      "Image: 907.jpg, OCR Prediction: \n",
      "Image: 908.jpg, OCR Prediction: \n",
      "Image: 909.jpg, OCR Prediction: \n",
      "Image: 910.jpg, OCR Prediction: \n",
      "Image: 911.jpg, OCR Prediction: \n",
      "Image: 912.jpg, OCR Prediction: \n",
      "Image: 913.jpg, OCR Prediction: \n",
      "Image: 914.jpg, OCR Prediction: \n",
      "Image: 915.jpg, OCR Prediction: \n",
      "Image: 917.jpg, OCR Prediction: \n",
      "Image: 918.jpg, OCR Prediction: \n",
      "Image: 919.jpg, OCR Prediction: \n",
      "Image: 920.jpg, OCR Prediction: \n",
      "Image: 921.jpg, OCR Prediction: \n",
      "Image: 922.jpg, OCR Prediction: \n",
      "Image: 923.jpg, OCR Prediction: \n",
      "Image: 924.jpg, OCR Prediction: \n",
      "Image: 925.jpg, OCR Prediction: \n",
      "Image: 926.jpg, OCR Prediction: \n",
      "Image: 927.jpg, OCR Prediction: \n",
      "Image: 928.jpg, OCR Prediction: \n",
      "Image: 929.jpg, OCR Prediction: \n",
      "Image: 930.jpg, OCR Prediction: \n",
      "Image: 931.jpg, OCR Prediction: \n",
      "Image: 932.jpg, OCR Prediction: \n",
      "Image: 933.jpg, OCR Prediction: \n",
      "Image: 934.jpg, OCR Prediction: \n",
      "Image: 935.jpg, OCR Prediction: \n",
      "Image: 936.jpg, OCR Prediction: \n",
      "Image: 937.jpg, OCR Prediction: \n",
      "Image: 938.jpg, OCR Prediction: \n",
      "Image: 939.jpg, OCR Prediction: \n",
      "Image: 940.jpg, OCR Prediction: \n",
      "Image: 941.jpg, OCR Prediction: \n",
      "Image: 942.jpg, OCR Prediction: \n",
      "Image: 943.jpg, OCR Prediction: \n",
      "Image: 944.jpg, OCR Prediction: \n",
      "Image: 945.jpg, OCR Prediction: \n",
      "Image: 946.jpg, OCR Prediction: \n",
      "Image: 947.jpg, OCR Prediction: \n",
      "Image: 948.jpg, OCR Prediction: \n",
      "Image: 949.jpg, OCR Prediction: \n",
      "Image: 950.jpg, OCR Prediction: \n",
      "Image: 951.jpg, OCR Prediction: \n",
      "Image: 952.jpg, OCR Prediction: \n",
      "Image: 953.jpg, OCR Prediction: \n",
      "Image: 954.jpg, OCR Prediction: \n",
      "Image: 955.jpg, OCR Prediction: \n",
      "Image: 956.jpg, OCR Prediction: \n",
      "Image: 957.jpg, OCR Prediction: \n",
      "Image: 958.jpg, OCR Prediction: \n",
      "Image: 959.jpg, OCR Prediction: \n",
      "Image: 960.jpg, OCR Prediction: \n",
      "Image: 961.jpg, OCR Prediction: \n",
      "Image: 962.jpg, OCR Prediction: \n",
      "Image: 963.jpg, OCR Prediction: \n",
      "Image: 964.jpg, OCR Prediction: \n",
      "Image: 965.jpg, OCR Prediction: \n",
      "Image: 966.jpg, OCR Prediction: \n",
      "Image: 967.jpg, OCR Prediction: \n",
      "Image: 968.jpg, OCR Prediction: \n",
      "Image: 969.jpg, OCR Prediction: \n",
      "Image: 970.jpg, OCR Prediction: \n",
      "Image: 971.jpg, OCR Prediction: \n",
      "Image: 972.jpg, OCR Prediction: \n",
      "Image: 973.jpg, OCR Prediction: \n",
      "Image: 974.jpg, OCR Prediction: \n",
      "Image: 975.jpg, OCR Prediction: \n",
      "Image: 976.jpg, OCR Prediction: \n",
      "Image: 977.jpg, OCR Prediction: \n",
      "Image: 978.jpg, OCR Prediction: \n",
      "Image: 979.jpg, OCR Prediction: \n",
      "Image: 981.jpg, OCR Prediction: \n",
      "Image: 982.jpg, OCR Prediction: \n",
      "Image: 983.jpg, OCR Prediction: \n",
      "Image: 984.jpg, OCR Prediction: \n",
      "Image: 985.jpg, OCR Prediction: \n",
      "Image: 986.jpg, OCR Prediction: \n",
      "Image: 987.jpg, OCR Prediction: \n",
      "Image: 988.jpg, OCR Prediction: \n",
      "Image: 989.jpg, OCR Prediction: \n",
      "Image: 990.jpg, OCR Prediction: \n",
      "Image: 991.jpg, OCR Prediction: \n",
      "Image: 992.jpg, OCR Prediction: \n",
      "Image: 993.jpg, OCR Prediction: \n",
      "Image: 994.jpg, OCR Prediction: \n",
      "Image: 995.jpg, OCR Prediction: \n",
      "Image: 996.jpg, OCR Prediction: \n",
      "Image: 997.jpg, OCR Prediction: \n",
      "Image: 998.jpg, OCR Prediction: \n",
      "Image: 999.jpg, OCR Prediction: \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "# Load trained CRNN model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "crnn_model = CRNN(num_classes=len(char_to_index)).to(device)\n",
    "crnn_model.load_state_dict(torch.load(\"crnn_best.pth\"))  # Load trained weights\n",
    "crnn_model.eval()\n",
    "\n",
    "# Define transformation for OCR\n",
    "ocr_transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((32, 128)),  # Ensure same input size as training\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "\n",
    "# Process each cropped plate\n",
    "output_folder = \"dataset\"\n",
    "cropped_plates = os.listdir(output_folder)\n",
    "\n",
    "for plate_name in cropped_plates:\n",
    "    plate_path = os.path.join(output_folder, plate_name)\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    plate_img = Image.open(plate_path).convert('L')\n",
    "    plate_img = ocr_transform(plate_img).unsqueeze(0).to(device)\n",
    "\n",
    "    # Predict text\n",
    "    with torch.no_grad():\n",
    "        output = crnn_model(plate_img)\n",
    "        predicted_indices = torch.argmax(output, dim=2).cpu().numpy()[0]\n",
    "        predicted_text = \"\".join([characters[p-1] for p in predicted_indices if 0 < p <= len(characters)])\n",
    "\n",
    "    print(f\"Image: {plate_name}, OCR Prediction: {predicted_text}\")  # Debugging output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Image Shape: torch.Size([1, 32, 128])\n",
      "OCR results saved to ocr_output.csv ✅\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define character set (A-Z, 0-9)\n",
    "characters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "char_to_index = {char: idx for idx, char in enumerate(characters)}\n",
    "\n",
    "# Load trained CRNN model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "crnn_model = CRNN(num_classes=len(char_to_index) + 1).to(device)  # +1 for PAD character\n",
    "crnn_model.load_state_dict(torch.load(\"crnn_best.pth\"))\n",
    "crnn_model.eval()\n",
    "\n",
    "ocr_transform = transforms.Compose([\n",
    "    transforms.Grayscale(),  # Ensure grayscale\n",
    "    transforms.Resize((32, 128)),  # Resize to training dimensions\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Must match training\n",
    "])\n",
    "\n",
    "# Test preprocessing on a sample image\n",
    "from PIL import Image\n",
    "plate_img = Image.open(\"dataset/1000.jpg\").convert('L')\n",
    "plate_img = ocr_transform(plate_img)\n",
    "\n",
    "print(\"Preprocessed Image Shape:\", plate_img.shape)  # Expected: (1, 32, 128)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define test images directory\n",
    "cropped_plate_folder = \"dataset\"\n",
    "output_csv = \"ocr_output.csv\"\n",
    "\n",
    "# Prepare results storage\n",
    "results = []\n",
    "\n",
    "# Process each cropped plate image\n",
    "for plate_name in os.listdir(cropped_plate_folder):\n",
    "    plate_path = os.path.join(cropped_plate_folder, plate_name)\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    plate_img = Image.open(plate_path).convert('L')\n",
    "    plate_img = ocr_transform(plate_img).unsqueeze(0).to(device)\n",
    "\n",
    "    # Predict text using CRNN\n",
    "    with torch.no_grad():\n",
    "        output = crnn_model(plate_img)\n",
    "        predicted_indices = torch.argmax(output, dim=2).cpu().numpy()[0]\n",
    "        predicted_text = \"\".join([characters[p] for p in predicted_indices if p < len(characters)])\n",
    "\n",
    "    # Convert to one-hot encoding\n",
    "    one_hot = [0] * 10  # Initialize 10-character empty list\n",
    "    for i, char in enumerate(predicted_text[:10]):  # Limit to 10 characters\n",
    "        if char in char_to_index:\n",
    "            one_hot[i] = char_to_index[char]  # Assign the index\n",
    "\n",
    "    # Append results\n",
    "    results.append([plate_name] + one_hot)\n",
    "\n",
    "# Convert to DataFrame and Save as CSV\n",
    "df = pd.DataFrame(results, columns=[\"id\"] + [str(i) for i in range(10)])\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"OCR results saved to {output_csv} ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.4597\n",
      "Epoch [2/10], Loss: 3.1923\n",
      "Epoch [3/10], Loss: 2.5816\n",
      "Epoch [4/10], Loss: 2.6029\n",
      "Epoch [5/10], Loss: 2.6147\n",
      "Epoch [6/10], Loss: 2.6078\n",
      "Epoch [7/10], Loss: 2.6001\n",
      "Epoch [8/10], Loss: 2.5929\n",
      "Epoch [9/10], Loss: 2.5869\n",
      "Epoch [10/10], Loss: 2.5571\n",
      "✅ Retraining complete!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "crnn_model = CRNN(num_classes=37).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(crnn_model.parameters(), lr=0.001)\n",
    "criterion = nn.CTCLoss(blank=0)  # Use 0 for blank character\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    crnn_model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = crnn_model(images)\n",
    "\n",
    "        input_lengths = torch.full((outputs.size(0),), outputs.size(1), dtype=torch.long).to(device)\n",
    "        target_lengths = torch.sum(labels != 0, dim=1).to(device)\n",
    "\n",
    "        loss = criterion(outputs.permute(1, 0, 2), labels, input_lengths, target_lengths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Save model\n",
    "torch.save(crnn_model.state_dict(), \"crnn_best.pth\")\n",
    "print(\"✅ Retraining complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR Output for known_good_plate.jpg: \n"
     ]
    }
   ],
   "source": [
    "plate_img = Image.open(\"dataset/911.jpg\").convert('L')\n",
    "plate_img = ocr_transform(plate_img).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = crnn_model(plate_img)\n",
    "    predicted_indices = torch.argmax(output, dim=2).cpu().numpy()[0]\n",
    "    predicted_text = \"\".join([characters[p-1] for p in predicted_indices if 0 < p <= len(characters)])\n",
    "\n",
    "print(\"OCR Output for known_good_plate.jpg:\", predicted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded OCR results saved to ocr_onehot.csv\n",
      "Plain text OCR results saved to ocr_plain.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import easyocr\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "test_folder = \"dataset\"\n",
    "onehot_csv = \"ocr_onehot.csv\"\n",
    "plain_csv = \"ocr_plain.csv\"\n",
    "\n",
    "# Initialize EasyOCR reader\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# List all image files in the test folder\n",
    "image_files = [f for f in os.listdir(test_folder) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "# Store results\n",
    "ocr_onehot_results = []\n",
    "ocr_plain_results = []\n",
    "\n",
    "# Header row for one-hot encoded CSV\n",
    "onehot_columns = [\"id\"] + [str(i) for i in range(10)]\n",
    "\n",
    "# Process each image\n",
    "for img_name in image_files:\n",
    "    img_path = os.path.join(test_folder, img_name)\n",
    "\n",
    "    # Perform OCR using EasyOCR\n",
    "    result = reader.readtext(img_path)\n",
    "\n",
    "    # Extract detected text\n",
    "    detected_text = \"\".join([d[1] for d in result]) if result else \"\"\n",
    "\n",
    "    # Store non-one-hot encoded result\n",
    "    ocr_plain_results.append([img_name, detected_text])\n",
    "\n",
    "    # Initialize one-hot encoding for digits 0-9\n",
    "    digit_counts = {str(i): 0 for i in range(10)}\n",
    "\n",
    "    # Update one-hot encoding based on detected digits\n",
    "    found_digit = False\n",
    "    for char in detected_text:\n",
    "        if char.isdigit():\n",
    "            digit_counts[char] = 1\n",
    "            found_digit = True\n",
    "\n",
    "    # Create row data\n",
    "    row_data = [img_name] + list(digit_counts.values()) if found_digit else [img_name] + [\"\"] * 10\n",
    "    ocr_onehot_results.append(row_data)\n",
    "\n",
    "# Save one-hot encoded results to CSV\n",
    "df_onehot = pd.DataFrame(ocr_onehot_results, columns=onehot_columns)\n",
    "df_onehot.to_csv(onehot_csv, index=False)\n",
    "\n",
    "# Save plain text results to CSV\n",
    "df_plain = pd.DataFrame(ocr_plain_results, columns=[\"id\", \"Detected_Text\"])\n",
    "df_plain.to_csv(plain_csv, index=False)\n",
    "\n",
    "print(f\"One-hot encoded OCR results saved to {onehot_csv}\")\n",
    "print(f\"Plain text OCR results saved to {plain_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
