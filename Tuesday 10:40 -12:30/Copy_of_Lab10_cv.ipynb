{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-gBG_6cBd99-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.restoration import denoise_wavelet, estimate_sigma\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "from skimage import img_as_float, img_as_ubyte\n",
    "from skimage.util import random_noise\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_q3T5EF0ewbc"
   },
   "outputs": [],
   "source": [
    "def add_noise_to_image(image, noise_type='gaussian', amount=0.05):\n",
    "    \"\"\"Add noise to an image for testing denoising methods.\"\"\"\n",
    "    float_img = img_as_float(image)\n",
    "    noisy_img = random_noise(float_img, mode=noise_type, var=amount)\n",
    "    return noisy_img, float_img\n",
    "\n",
    "def median_filter_denoise(noisy_img, kernel_size=3):\n",
    "    \"\"\"Apply median filter for denoising.\"\"\"\n",
    "    denoised = cv2.medianBlur(img_as_ubyte(noisy_img), kernel_size)\n",
    "    return img_as_float(denoised)\n",
    "\n",
    "def wavelet_denoise(noisy_img, wavelet='db1', mode='soft'):\n",
    "    \"\"\"Apply wavelet transform for denoising.\"\"\"\n",
    "    sigma_est = estimate_sigma(noisy_img, average_sigmas=True)\n",
    "    return denoise_wavelet(noisy_img, sigma=sigma_est, wavelet=wavelet, mode=mode,\n",
    "                         rescale_sigma=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJvEyxeBewdw"
   },
   "outputs": [],
   "source": [
    "# Simple implementation of Noise2Void concept\n",
    "def noise2void_denoise(noisy_img, patch_size=5):\n",
    "    \"\"\"Simplified version of Noise2Void using basic masking approach.\"\"\"\n",
    "    h, w = noisy_img.shape[:2]\n",
    "    result = np.copy(noisy_img)\n",
    "\n",
    "    # For simplicity, we'll use a moving window approach with median values\n",
    "    for i in range(patch_size, h-patch_size):\n",
    "        for j in range(patch_size, w-patch_size):\n",
    "            # Take surrounding patch but exclude center pixel\n",
    "            patch = noisy_img[i-patch_size:i+patch_size+1, j-patch_size:j+patch_size+1].copy()\n",
    "            center = patch[patch_size, patch_size].copy()\n",
    "            patch[patch_size, patch_size] = 0  # Mask center\n",
    "\n",
    "            # Use median of neighborhood as estimate\n",
    "            median_val = np.median(patch[patch != 0])\n",
    "            result[i, j] = median_val\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cf32c10RewgI"
   },
   "outputs": [],
   "source": [
    "def compare_denoising_methods(image_path, noise_type='gaussian', noise_amount=0.05):\n",
    "    \"\"\"Compare different denoising methods and calculate metrics.\"\"\"\n",
    "    # Load image and convert to grayscale if needed\n",
    "    original = cv2.imread(image_path)\n",
    "    if original is None:\n",
    "        raise ValueError(f\"Could not read image at {image_path}\")\n",
    "\n",
    "    if len(original.shape) == 3 and original.shape[2] == 3:\n",
    "        original = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Normalize to [0, 1] range\n",
    "    original_norm = img_as_float(original)\n",
    "\n",
    "    # Add noise\n",
    "    noisy_img, _ = add_noise_to_image(original_norm, noise_type, noise_amount)\n",
    "\n",
    "    # Apply denoising methods\n",
    "    start_time = time.time()\n",
    "    median_denoised = median_filter_denoise(noisy_img)\n",
    "    median_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    wavelet_denoised = wavelet_denoise(noisy_img)\n",
    "    wavelet_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    n2v_denoised = noise2void_denoise(noisy_img)\n",
    "    n2v_time = time.time() - start_time\n",
    "    # Calculate metrics\n",
    "    results = {\n",
    "        'Method': ['Median Filter', 'Wavelet Denoising', 'Noise2Void'],\n",
    "        'PSNR': [\n",
    "            psnr(original_norm, median_denoised),\n",
    "            psnr(original_norm, wavelet_denoised),\n",
    "            psnr(original_norm, n2v_denoised)\n",
    "        ],\n",
    "        'SSIM': [\n",
    "            # Specify data_range for ssim calculations\n",
    "            ssim(original_norm, median_denoised, data_range=1.0),  # Assuming data range is [0, 1]\n",
    "            ssim(original_norm, wavelet_denoised, data_range=1.0),  # Assuming data range is [0, 1]\n",
    "            ssim(original_norm, n2v_denoised, data_range=1.0)  # Assuming data range is [0, 1]\n",
    "        ],\n",
    "        'MSE': [\n",
    "            mse(original_norm, median_denoised),\n",
    "            mse(original_norm, wavelet_denoised),\n",
    "            mse(original_norm, n2v_denoised)\n",
    "        ],\n",
    "        'Time (s)': [median_time, wavelet_time, n2v_time]\n",
    "    }\n",
    "\n",
    "    # Display results\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.imshow(original_norm, cmap='gray')\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.imshow(noisy_img, cmap='gray')\n",
    "    plt.title(f'Noisy ({noise_type})')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.imshow(median_denoised, cmap='gray')\n",
    "    plt.title(f'Median Filter\\nPSNR: {results[\"PSNR\"][0]:.2f}, SSIM: {results[\"SSIM\"][0]:.2f}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.imshow(wavelet_denoised, cmap='gray')\n",
    "    plt.title(f'Wavelet Denoising\\nPSNR: {results[\"PSNR\"][1]:.2f}, SSIM: {results[\"SSIM\"][1]:.2f}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.imshow(n2v_denoised, cmap='gray')\n",
    "    plt.title(f'Noise2Void\\nPSNR: {results[\"PSNR\"][2]:.2f}, SSIM: {results[\"SSIM\"][2]:.2f}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('denoising_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Print metrics table\n",
    "    print(\"\\nDenoising Methods Comparison:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Method':<20} {'PSNR':<10} {'SSIM':<10} {'MSE':<10} {'Time (s)':<10}\")\n",
    "    print(\"-\" * 80)\n",
    "    for i in range(len(results['Method'])):\n",
    "        print(f\"{results['Method'][i]:<20} {results['PSNR'][i]:<10.4f} {results['SSIM'][i]:<10.4f} {results['MSE'][i]:<10.4f} {results['Time (s)'][i]:<10.4f}\")\n",
    "\n",
    "    return results, {\n",
    "        'original': original_norm,\n",
    "        'noisy': noisy_img,\n",
    "        'median': median_denoised,\n",
    "        'wavelet': wavelet_denoised,\n",
    "        'n2v': n2v_denoised\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ClLf5rEewie"
   },
   "outputs": [],
   "source": [
    "def extract_frames(video_path, output_folder='extracted_frames', frame_step=1):\n",
    "    \"\"\"Extract frames from a video file and save them as images.\"\"\"\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Could not open video file {video_path}\")\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = frame_count / fps\n",
    "\n",
    "    print(f\"Video Information:\")\n",
    "    print(f\"FPS: {fps}\")\n",
    "    print(f\"Frame Count: {frame_count}\")\n",
    "    print(f\"Duration: {duration:.2f} seconds\")\n",
    "\n",
    "    # Extract frames\n",
    "    count = 0\n",
    "    frames_saved = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Save frame at the specified interval\n",
    "        if count % frame_step == 0:\n",
    "            frame_filename = os.path.join(output_folder, f\"frame_{frames_saved:04d}.jpg\")\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "            frames_saved += 1\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Extracted {frames_saved} frames to {output_folder}\")\n",
    "    return output_folder, fps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6cwvLqWiewqj"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PART 3: PROCESS VIDEO FRAMES AND CREATE NEW VIDEOS\n",
    "\"\"\"\n",
    "def process_video_frames(video_path, output_folder='processed_videos'):\n",
    "    \"\"\"Process video frames with different techniques and create new videos.\"\"\"\n",
    "    # Create output folders\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    frames_folder = os.path.join(output_folder, 'frames')\n",
    "    os.makedirs(frames_folder, exist_ok=True)\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Could not open video file {video_path}\")\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Define video writers for each processing technique\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    adaptive_thresh_video = cv2.VideoWriter(os.path.join(output_folder, 'adaptive_threshold.mp4'),\n",
    "                                           fourcc, fps, (width, height), False)\n",
    "    gaussian_video = cv2.VideoWriter(os.path.join(output_folder, 'gaussian_smoothing.mp4'),\n",
    "                                    fourcc, fps, (width, height))\n",
    "    canny_video = cv2.VideoWriter(os.path.join(output_folder, 'canny_edge.mp4'),\n",
    "                                 fourcc, fps, (width, height), False)\n",
    "    bitwise_not_video = cv2.VideoWriter(os.path.join(output_folder, 'bitwise_not.mp4'),\n",
    "                                       fourcc, fps, (width, height))\n",
    "\n",
    "    # Process frames\n",
    "    frame_set = []  # Store some frames for the collage\n",
    "    frame_step = max(1, frame_count // 25)  # Store about 25 frames for collage\n",
    "\n",
    "    count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert to grayscale for some operations\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # 1. Adaptive Thresholding\n",
    "        adaptive_thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                               cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "        # 2. Gaussian Smoothing\n",
    "        gaussian = cv2.GaussianBlur(frame, (15, 15), 0)\n",
    "\n",
    "        # 3. Canny Edge Detection\n",
    "        canny = cv2.Canny(gray, 100, 200)\n",
    "\n",
    "        # 4. Bitwise Not\n",
    "        bitwise_not = cv2.bitwise_not(frame)\n",
    "\n",
    "        # Write frames to videos\n",
    "        adaptive_thresh_video.write(adaptive_thresh)\n",
    "        gaussian_video.write(gaussian)\n",
    "        canny_video.write(canny)\n",
    "        bitwise_not_video.write(bitwise_not)\n",
    "\n",
    "        # Save frames for collage\n",
    "        if count % frame_step == 0:\n",
    "            # Save original and processed frames\n",
    "            cv2.imwrite(os.path.join(frames_folder, f\"original_{count:04d}.jpg\"), frame)\n",
    "            cv2.imwrite(os.path.join(frames_folder, f\"adaptive_{count:04d}.jpg\"), adaptive_thresh)\n",
    "            cv2.imwrite(os.path.join(frames_folder, f\"gaussian_{count:04d}.jpg\"), gaussian)\n",
    "            cv2.imwrite(os.path.join(frames_folder, f\"canny_{count:04d}.jpg\"), canny)\n",
    "            cv2.imwrite(os.path.join(frames_folder, f\"bitwise_{count:04d}.jpg\"), bitwise_not)\n",
    "\n",
    "            # Store for collage\n",
    "            frame_set.append({\n",
    "                'original': frame.copy(),\n",
    "                'adaptive': adaptive_thresh.copy(),\n",
    "                'gaussian': gaussian.copy(),\n",
    "                'canny': canny.copy(),\n",
    "                'bitwise': bitwise_not.copy()\n",
    "            })\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    adaptive_thresh_video.release()\n",
    "    gaussian_video.release()\n",
    "    canny_video.release()\n",
    "    bitwise_not_video.release()\n",
    "\n",
    "    # Create collage\n",
    "    create_collage(frame_set, os.path.join(output_folder, 'video_processing_collage.jpg'))\n",
    "\n",
    "    print(f\"Processed {count} frames and created videos in {output_folder}\")\n",
    "    return output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDvxnzjofPDq"
   },
   "outputs": [],
   "source": [
    "def create_collage(frame_set, output_path):\n",
    "    \"\"\"Create a collage from the processed frames.\"\"\"\n",
    "    if not frame_set:\n",
    "        print(\"No frames to create collage\")\n",
    "        return\n",
    "\n",
    "    # Determine dimensions\n",
    "    num_frames = len(frame_set)\n",
    "    num_types = 5  # original, adaptive, gaussian, canny, bitwise\n",
    "\n",
    "    # Let's make a grid with rows = num_types and cols = min(5, num_frames)\n",
    "    cols = min(5, num_frames)\n",
    "    rows = num_types\n",
    "\n",
    "    # Get frame dimensions from first frame\n",
    "    f_height, f_width = frame_set[0]['original'].shape[:2]\n",
    "\n",
    "    # Create blank canvas\n",
    "    collage_width = cols * f_width\n",
    "    collage_height = rows * f_height\n",
    "    collage = np.zeros((collage_height, collage_width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Fill the collage\n",
    "    for i, frame_dict in enumerate(frame_set[:cols]):\n",
    "        # Original\n",
    "        collage[0:f_height, i*f_width:(i+1)*f_width] = frame_dict['original']\n",
    "\n",
    "        # Adaptive threshold (convert to BGR for display)\n",
    "        adaptive_bgr = cv2.cvtColor(frame_dict['adaptive'], cv2.COLOR_GRAY2BGR)\n",
    "        collage[f_height:2*f_height, i*f_width:(i+1)*f_width] = adaptive_bgr\n",
    "\n",
    "        # Gaussian blur\n",
    "        collage[2*f_height:3*f_height, i*f_width:(i+1)*f_width] = frame_dict['gaussian']\n",
    "\n",
    "        # Canny edges (convert to BGR for display)\n",
    "        canny_bgr = cv2.cvtColor(frame_dict['canny'], cv2.COLOR_GRAY2BGR)\n",
    "        collage[3*f_height:4*f_height, i*f_width:(i+1)*f_width] = canny_bgr\n",
    "\n",
    "        # Bitwise not\n",
    "        collage[4*f_height:5*f_height, i*f_width:(i+1)*f_width] = frame_dict['bitwise']\n",
    "\n",
    "    # Add labels\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    labels = ['Original', 'Adaptive Threshold', 'Gaussian Blur', 'Canny Edge', 'Bitwise Not']\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        y_pos = i * f_height + 30\n",
    "        cv2.putText(collage, label, (10, y_pos), font, 1, (255, 255, 255), 2)\n",
    "\n",
    "    # Save the collage\n",
    "    cv2.imwrite(output_path, collage)\n",
    "    print(f\"Collage saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rFSdi-mfg3YO",
    "outputId": "6640a5cf-04db-4da3-a83b-95bd227ab1dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyWavelets\n",
      "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from PyWavelets) (2.0.2)\n",
      "Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyWavelets\n",
      "Successfully installed PyWavelets-1.8.0\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.15.2)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.3.30)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyWavelets\n",
    "!pip install opencv-python numpy matplotlib scikit-image tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nphdpjBafSSZ",
    "outputId": "b8a3653c-72a5-4b1e-a6dd-e66b5bf0cacb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TASK 1: IMAGE DENOISING COMPARISON\n",
      "==================================================\n",
      "\n",
      "Denoising Methods Comparison:\n",
      "--------------------------------------------------------------------------------\n",
      "Method               PSNR       SSIM       MSE        Time (s)  \n",
      "--------------------------------------------------------------------------------\n",
      "Median Filter        14.0352    0.2165     0.0395     0.0007    \n",
      "Wavelet Denoising    14.4659    0.1517     0.0358     0.0057    \n",
      "Noise2Void           14.0442    0.1116     0.0394     2.1805    \n",
      "\n",
      "==================================================\n",
      "TASK 2: EXTRACT FRAMES FROM VIDEO\n",
      "==================================================\n",
      "Video Information:\n",
      "FPS: 25.0\n",
      "Frame Count: 132\n",
      "Duration: 5.28 seconds\n",
      "Extracted 27 frames to extracted_frames\n",
      "\n",
      "==================================================\n",
      "TASK 3: PROCESS VIDEO FRAMES\n",
      "==================================================\n",
      "Collage saved to processed_videos/video_processing_collage.jpg\n",
      "Processed 132 frames and created videos in processed_videos\n",
      "\n",
      "All tasks completed!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MAIN FUNCTION TO RUN ALL TASKS\n",
    "\"\"\"\n",
    "def main():\n",
    "    # TASK 1: Image Denoising Comparison\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TASK 1: IMAGE DENOISING COMPARISON\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # You can replace this with the path to your own image\n",
    "    # If you don't have an image, uncomment the code below to create a sample image\n",
    "    \"\"\"\n",
    "    # Create a sample image if needed\n",
    "    sample_img = np.zeros((300, 300), dtype=np.uint8)\n",
    "    cv2.circle(sample_img, (150, 150), 100, 255, -1)\n",
    "    cv2.rectangle(sample_img, (50, 50), (250, 250), 128, 3)\n",
    "    cv2.imwrite('sample_image.jpg', sample_img)\n",
    "    image_path = 'sample_image.jpg'\n",
    "    \"\"\"\n",
    "\n",
    "    # Replace with your image path\n",
    "    image_path = '/content/denoise.png'\n",
    "\n",
    "    # Uncomment the line below and provide your image path to run the denoising comparison\n",
    "    results, images = compare_denoising_methods(image_path, noise_type='gaussian', noise_amount=0.05)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TASK 2: EXTRACT FRAMES FROM VIDEO\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Replace with your video path\n",
    "    video_path = '/content/sample.mp4'\n",
    "\n",
    "    # Uncomment the line below and provide your video path to extract frames\n",
    "    frames_folder, fps = extract_frames(video_path, output_folder='extracted_frames', frame_step=5)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TASK 3: PROCESS VIDEO FRAMES\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Use the same video path or specify a different one\n",
    "    # Uncomment the line below and provide your video path to process the video\n",
    "    output_folder = process_video_frames(video_path, output_folder='processed_videos')\n",
    "\n",
    "    print(\"\\nAll tasks completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
